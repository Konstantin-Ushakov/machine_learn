{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54d6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, v_measure_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn import tree, naive_bayes\n",
    "from sklearn.utils._testing import ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d9e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ab15b",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467833",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7277957",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9412d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank_additional_preprocessed.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fa3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>previous_0</th>\n",
       "      <th>previous_1</th>\n",
       "      <th>previous_2</th>\n",
       "      <th>previous_3</th>\n",
       "      <th>previous_4</th>\n",
       "      <th>previous_5</th>\n",
       "      <th>previous_6</th>\n",
       "      <th>previous_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  campaign  pdays  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0       56         1    999           1.1          93.994          -36.4   \n",
       "1       57         1    999           1.1          93.994          -36.4   \n",
       "2       37         1    999           1.1          93.994          -36.4   \n",
       "3       40         1    999           1.1          93.994          -36.4   \n",
       "4       56         1    999           1.1          93.994          -36.4   \n",
       "...    ...       ...    ...           ...             ...            ...   \n",
       "41183   73         1    999          -1.1          94.767          -50.8   \n",
       "41184   46         1    999          -1.1          94.767          -50.8   \n",
       "41185   56         2    999          -1.1          94.767          -50.8   \n",
       "41186   44         1    999          -1.1          94.767          -50.8   \n",
       "41187   74         3    999          -1.1          94.767          -50.8   \n",
       "\n",
       "       euribor3m  nr.employed  y  job_admin.  ...  poutcome_nonexistent  \\\n",
       "0          4.857       5191.0  0           0  ...                     1   \n",
       "1          4.857       5191.0  0           0  ...                     1   \n",
       "2          4.857       5191.0  0           0  ...                     1   \n",
       "3          4.857       5191.0  0           1  ...                     1   \n",
       "4          4.857       5191.0  0           0  ...                     1   \n",
       "...          ...          ... ..         ...  ...                   ...   \n",
       "41183      1.028       4963.6  1           0  ...                     1   \n",
       "41184      1.028       4963.6  0           0  ...                     1   \n",
       "41185      1.028       4963.6  0           0  ...                     1   \n",
       "41186      1.028       4963.6  1           0  ...                     1   \n",
       "41187      1.028       4963.6  0           0  ...                     0   \n",
       "\n",
       "       poutcome_success  previous_0  previous_1  previous_2  previous_3  \\\n",
       "0                     0           1           0           0           0   \n",
       "1                     0           1           0           0           0   \n",
       "2                     0           1           0           0           0   \n",
       "3                     0           1           0           0           0   \n",
       "4                     0           1           0           0           0   \n",
       "...                 ...         ...         ...         ...         ...   \n",
       "41183                 0           1           0           0           0   \n",
       "41184                 0           1           0           0           0   \n",
       "41185                 0           1           0           0           0   \n",
       "41186                 0           1           0           0           0   \n",
       "41187                 0           0           1           0           0   \n",
       "\n",
       "       previous_4  previous_5  previous_6  previous_7  \n",
       "0               0           0           0           0  \n",
       "1               0           0           0           0  \n",
       "2               0           0           0           0  \n",
       "3               0           0           0           0  \n",
       "4               0           0           0           0  \n",
       "...           ...         ...         ...         ...  \n",
       "41183           0           0           0           0  \n",
       "41184           0           0           0           0  \n",
       "41185           0           0           0           0  \n",
       "41186           0           0           0           0  \n",
       "41187           0           0           0           0  \n",
       "\n",
       "[41188 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f505b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 70 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age                            41188 non-null  int64  \n",
      " 1   campaign                       41188 non-null  int64  \n",
      " 2   pdays                          41188 non-null  int64  \n",
      " 3   emp.var.rate                   41188 non-null  float64\n",
      " 4   cons.price.idx                 41188 non-null  float64\n",
      " 5   cons.conf.idx                  41188 non-null  float64\n",
      " 6   euribor3m                      41188 non-null  float64\n",
      " 7   nr.employed                    41188 non-null  float64\n",
      " 8   y                              41188 non-null  int64  \n",
      " 9   job_admin.                     41188 non-null  int64  \n",
      " 10  job_blue-collar                41188 non-null  int64  \n",
      " 11  job_entrepreneur               41188 non-null  int64  \n",
      " 12  job_housemaid                  41188 non-null  int64  \n",
      " 13  job_management                 41188 non-null  int64  \n",
      " 14  job_retired                    41188 non-null  int64  \n",
      " 15  job_self-employed              41188 non-null  int64  \n",
      " 16  job_services                   41188 non-null  int64  \n",
      " 17  job_student                    41188 non-null  int64  \n",
      " 18  job_technician                 41188 non-null  int64  \n",
      " 19  job_unemployed                 41188 non-null  int64  \n",
      " 20  job_unknown                    41188 non-null  int64  \n",
      " 21  marital_divorced               41188 non-null  int64  \n",
      " 22  marital_married                41188 non-null  int64  \n",
      " 23  marital_single                 41188 non-null  int64  \n",
      " 24  marital_unknown                41188 non-null  int64  \n",
      " 25  education_basic.4y             41188 non-null  int64  \n",
      " 26  education_basic.6y             41188 non-null  int64  \n",
      " 27  education_basic.9y             41188 non-null  int64  \n",
      " 28  education_high.school          41188 non-null  int64  \n",
      " 29  education_illiterate           41188 non-null  int64  \n",
      " 30  education_professional.course  41188 non-null  int64  \n",
      " 31  education_university.degree    41188 non-null  int64  \n",
      " 32  education_unknown              41188 non-null  int64  \n",
      " 33  default_no                     41188 non-null  int64  \n",
      " 34  default_unknown                41188 non-null  int64  \n",
      " 35  default_yes                    41188 non-null  int64  \n",
      " 36  housing_no                     41188 non-null  int64  \n",
      " 37  housing_unknown                41188 non-null  int64  \n",
      " 38  housing_yes                    41188 non-null  int64  \n",
      " 39  loan_no                        41188 non-null  int64  \n",
      " 40  loan_unknown                   41188 non-null  int64  \n",
      " 41  loan_yes                       41188 non-null  int64  \n",
      " 42  contact_cellular               41188 non-null  int64  \n",
      " 43  contact_telephone              41188 non-null  int64  \n",
      " 44  month_apr                      41188 non-null  int64  \n",
      " 45  month_aug                      41188 non-null  int64  \n",
      " 46  month_dec                      41188 non-null  int64  \n",
      " 47  month_jul                      41188 non-null  int64  \n",
      " 48  month_jun                      41188 non-null  int64  \n",
      " 49  month_mar                      41188 non-null  int64  \n",
      " 50  month_may                      41188 non-null  int64  \n",
      " 51  month_nov                      41188 non-null  int64  \n",
      " 52  month_oct                      41188 non-null  int64  \n",
      " 53  month_sep                      41188 non-null  int64  \n",
      " 54  day_of_week_fri                41188 non-null  int64  \n",
      " 55  day_of_week_mon                41188 non-null  int64  \n",
      " 56  day_of_week_thu                41188 non-null  int64  \n",
      " 57  day_of_week_tue                41188 non-null  int64  \n",
      " 58  day_of_week_wed                41188 non-null  int64  \n",
      " 59  poutcome_failure               41188 non-null  int64  \n",
      " 60  poutcome_nonexistent           41188 non-null  int64  \n",
      " 61  poutcome_success               41188 non-null  int64  \n",
      " 62  previous_0                     41188 non-null  int64  \n",
      " 63  previous_1                     41188 non-null  int64  \n",
      " 64  previous_2                     41188 non-null  int64  \n",
      " 65  previous_3                     41188 non-null  int64  \n",
      " 66  previous_4                     41188 non-null  int64  \n",
      " 67  previous_5                     41188 non-null  int64  \n",
      " 68  previous_6                     41188 non-null  int64  \n",
      " 69  previous_7                     41188 non-null  int64  \n",
      "dtypes: float64(5), int64(65)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f37df4",
   "metadata": {},
   "source": [
    "Посмотрим на сбалансированность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3dc5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([36548,  4640], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, samples = np.unique(df.y, return_counts=True)\n",
    "labels, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682d222",
   "metadata": {},
   "source": [
    "Как мы видим, данные несбалансированы: данных класса 0 приблизительно в 10 раз больше, чем данных класса 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89256fbe",
   "metadata": {},
   "source": [
    "При таком дисбалансе при downsampling потеряется большое число информации, поэтому выполним upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714df301",
   "metadata": {},
   "source": [
    "Для того, чтобы данные из обучающей выборки не попали в тестовую, выполним разбиение на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b768829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(df_big, df_small, verbose=False):\n",
    "    if verbose:\n",
    "        print('Upsample from {} to {}'.format(len(df_small), len(df_big)))\n",
    "    df_small_copy = df_small.copy()\n",
    "    i = len(df_small)\n",
    "    while i < len(df_big):\n",
    "        if verbose:\n",
    "            print('GET i: {}'.format(i))\n",
    "        if i + len(df_small_copy) < len(df_big):\n",
    "            df_small = df_small.append(df_small_copy)\n",
    "            i += len(df_small_copy)\n",
    "        else:\n",
    "            df_small = df_small.append(df_small_copy.loc[np.random.permutation(len(df_small_copy))].loc[i % len(df_small_copy) : (len(df_big) - 1) % len(df_small_copy)])\n",
    "            i = len(df_small)\n",
    "    return df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4f20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df_big, df_small, verbose=False):\n",
    "    if verbose:\n",
    "        print('Downsample from {} to {}'.format(len(df_big), len(df_small)))\n",
    "    return df_big.loc[np.random.permutation(len(df_big))[:len(df_small)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62dd446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample from 36548 to 4640\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Upsample\n",
    "df_0 = df.loc[df.y == 0].reset_index(drop=True)\n",
    "df_0_train, df_0_test = train_test_split(df_0, test_size=0.2)\n",
    "\n",
    "df_1 = df.loc[df.y == 1].reset_index(drop=True)\n",
    "df_1_train, df_1_test = train_test_split(df_1, test_size=0.2)\n",
    "\n",
    "df_0_train = df_0_train.reset_index(drop=True)\n",
    "df_1_train = df_1_train.reset_index(drop=True)\n",
    "\n",
    "df_0_test = df_0_test.reset_index(drop=True)\n",
    "df_1_test = df_1_test.reset_index(drop=True)\n",
    "\n",
    "df_1_train_up = upsample(df_0_train, df_1_train, verbose=True)\n",
    "df_1_test_up = upsample(df_0_test, df_1_test, verbose=True)\n",
    "\n",
    "df_train = pd.concat([df_0_train, df_1_train_up], ignore_index=True)\n",
    "df_train = df_train.loc[np.random.permutation(len(df_train))]\n",
    "df_test = pd.concat([df_0_test, df_1_test_up], ignore_index=True)\n",
    "df_test = df_test.loc[np.random.permutation(len(df_test))]\n",
    "\n",
    "df_sample = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(df_train.shape, df_train[df_train.y == 0].shape, df_train[df_train.y == 1].shape)\n",
    "'''\n",
    "# Downsample\n",
    "# num_obj = 1000\n",
    "df_0 = df.loc[df.y == 0].reset_index(drop=True)\n",
    "df_1 = df.loc[df.y == 1].reset_index(drop=True)\n",
    "# df_1 = df_1.loc[np.random.permutation(len(df_1))[:num_obj]]\n",
    "df_0 = downsample(df_0, df_1, verbose=True)\n",
    "\n",
    "df_sample = pd.concat([df_0, df_1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d16130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9280, 69), (9280,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sample.drop(['y'], axis=1)\n",
    "y = df_sample.y\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b6181",
   "metadata": {},
   "source": [
    "Для удобства обработки разделим признаки на категориальные и вещественные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68df38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = np.array(['age', 'campaign', 'pdays', 'emp.var.rate', 'cons.price.idx', \n",
    "           'cons.conf.idx', 'euribor3m', 'nr.employed'])\n",
    "X_numeric = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "194dcfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))\n",
    "X_categorical = X[categorical_cols]\n",
    "for col in categorical_cols:\n",
    "    X_categorical[col] = X_categorical[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96f7bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9280 entries, 0 to 9279\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   contact_telephone              9280 non-null   string\n",
      " 1   marital_divorced               9280 non-null   string\n",
      " 2   poutcome_nonexistent           9280 non-null   string\n",
      " 3   contact_cellular               9280 non-null   string\n",
      " 4   month_jul                      9280 non-null   string\n",
      " 5   day_of_week_fri                9280 non-null   string\n",
      " 6   education_professional.course  9280 non-null   string\n",
      " 7   day_of_week_mon                9280 non-null   string\n",
      " 8   previous_1                     9280 non-null   string\n",
      " 9   previous_3                     9280 non-null   string\n",
      " 10  day_of_week_wed                9280 non-null   string\n",
      " 11  previous_2                     9280 non-null   string\n",
      " 12  month_aug                      9280 non-null   string\n",
      " 13  default_yes                    9280 non-null   string\n",
      " 14  month_jun                      9280 non-null   string\n",
      " 15  previous_4                     9280 non-null   string\n",
      " 16  default_no                     9280 non-null   string\n",
      " 17  housing_unknown                9280 non-null   string\n",
      " 18  marital_single                 9280 non-null   string\n",
      " 19  job_unemployed                 9280 non-null   string\n",
      " 20  job_retired                    9280 non-null   string\n",
      " 21  job_services                   9280 non-null   string\n",
      " 22  job_management                 9280 non-null   string\n",
      " 23  education_basic.6y             9280 non-null   string\n",
      " 24  month_sep                      9280 non-null   string\n",
      " 25  loan_yes                       9280 non-null   string\n",
      " 26  education_university.degree    9280 non-null   string\n",
      " 27  education_high.school          9280 non-null   string\n",
      " 28  previous_0                     9280 non-null   string\n",
      " 29  loan_unknown                   9280 non-null   string\n",
      " 30  poutcome_success               9280 non-null   string\n",
      " 31  job_blue-collar                9280 non-null   string\n",
      " 32  month_mar                      9280 non-null   string\n",
      " 33  day_of_week_tue                9280 non-null   string\n",
      " 34  previous_6                     9280 non-null   string\n",
      " 35  job_self-employed              9280 non-null   string\n",
      " 36  day_of_week_thu                9280 non-null   string\n",
      " 37  education_unknown              9280 non-null   string\n",
      " 38  job_student                    9280 non-null   string\n",
      " 39  previous_7                     9280 non-null   string\n",
      " 40  loan_no                        9280 non-null   string\n",
      " 41  job_unknown                    9280 non-null   string\n",
      " 42  education_basic.4y             9280 non-null   string\n",
      " 43  education_illiterate           9280 non-null   string\n",
      " 44  housing_yes                    9280 non-null   string\n",
      " 45  default_unknown                9280 non-null   string\n",
      " 46  month_nov                      9280 non-null   string\n",
      " 47  month_may                      9280 non-null   string\n",
      " 48  job_admin.                     9280 non-null   string\n",
      " 49  job_entrepreneur               9280 non-null   string\n",
      " 50  job_housemaid                  9280 non-null   string\n",
      " 51  month_dec                      9280 non-null   string\n",
      " 52  job_technician                 9280 non-null   string\n",
      " 53  month_apr                      9280 non-null   string\n",
      " 54  poutcome_failure               9280 non-null   string\n",
      " 55  marital_married                9280 non-null   string\n",
      " 56  housing_no                     9280 non-null   string\n",
      " 57  previous_5                     9280 non-null   string\n",
      " 58  marital_unknown                9280 non-null   string\n",
      " 59  education_basic.9y             9280 non-null   string\n",
      " 60  month_oct                      9280 non-null   string\n",
      "dtypes: string(61)\n",
      "memory usage: 4.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac747ba9",
   "metadata": {},
   "source": [
    "Разделим данные на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e523d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(X, X_categorical, X_numeric, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1f80d",
   "metadata": {},
   "source": [
    "Нормализируем значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f06a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_numeric)\n",
    "\n",
    "X_train_num_sc = scaler.transform(X_train_num)\n",
    "X_test_num_sc = scaler.transform(X_test_num)\n",
    "X_num_sc = scaler.transform(X_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a922c",
   "metadata": {},
   "source": [
    "Соединяем воедино все значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01a2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = np.hstack((X_train_num_sc, X_train_cat))\n",
    "X_test_transform = np.hstack((X_test_num_sc, X_test_cat))\n",
    "X_transform = np.hstack((X_num_sc, X_categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b744b",
   "metadata": {},
   "source": [
    "Для некоторых алгоритмов введено условие неотрицательности, реализуем его"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6aeef",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45784d",
   "metadata": {},
   "source": [
    "Напишем методы, которые будут обучать модель и предсказывать результат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bb201",
   "metadata": {},
   "source": [
    "Данный метод будет выводить на печать метрики в задаче [классификации](https://scikit-learn.org/0.20/modules/classes.html#classification-metrics) и [кластеризации](https://scikit-learn.org/0.20/modules/classes.html#clustering-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5802af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(X, y_true, y_pred, type_task='classification'):\n",
    "    if type_task == 'classification':\n",
    "        print('Confusion matrix:')\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        print('Classification report:')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    elif type_task == 'clustering':\n",
    "        print('Silhouette score:')\n",
    "        print(silhouette_score(X, y_pred))\n",
    "        print('V measure score:')\n",
    "        print(v_measure_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327a164",
   "metadata": {},
   "source": [
    "Функция обучения модели и предсказывания значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b10bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X_train, X_test, y_train, y_test, type_task='classification', \n",
    "                model=tree.DecisionTreeClassifier, init_parameters={}, custom_predict=None,\n",
    "                use_test=True, \n",
    "                verbose=False, draw=False, **parameters):\n",
    "    \n",
    "    if not use_test:\n",
    "        X_test = X_train\n",
    "        y_test = y_train\n",
    "    if custom_predict:\n",
    "        X_test, y_test, y_pred = custom_predict(X_train, X_test, y_train, y_test, type_task, model, init_parameters, verbose=verbose, draw=draw, **parameters)\n",
    "    elif type_task == 'classification':\n",
    "        print('Start fit model and predict values')\n",
    "        classifier_model = model(**init_parameters)\n",
    "        clf_model = GridSearchCV(classifier_model, parameters)\n",
    "        clf_model.fit(X_train, y_train)\n",
    "        # Get best model\n",
    "        best_est = clf_model.best_estimator_\n",
    "        if verbose:\n",
    "            print('GridSearchCV: best estimator:\\n{},\\nwith best parameters:\\n{}'.format(clf_model.best_estimator_, clf_model.best_params_))\n",
    "        # Predict value\n",
    "        y_pred = best_est.predict(X_test)\n",
    "    elif type_task == 'clustering':\n",
    "        print('Start fit model and predict values')\n",
    "        classifier_model = model(**init_parameters)\n",
    "        classifier_model.fit(X_train)\n",
    "        # Обучаем модель\n",
    "        y_pred = classifier_model.predict(X_test)\n",
    "    \n",
    "    if verbose:\n",
    "        print_metrics(X_test, y_test, y_pred, type_task=type_task)\n",
    "    if draw:\n",
    "        if(X_test.shape[1] == 2):\n",
    "            plot_2d(X_test[:, 0], X_test[:, 1], y_pred)\n",
    "        elif(X_test.shape[1] == 3):\n",
    "            plot_3d(X_test[:, 0], X_test[:, 1], X_test[:, 2], y_pred)\n",
    "        else:\n",
    "            while X_test.shape[1] < 3:\n",
    "                print('Add useless zeros dimension to dataset')\n",
    "                X_test = np.hstack((X_test, np.zeros((X_test.shape[0], 1))))\n",
    "            pca = PCA(n_components=3)\n",
    "            pca_3d = pca.fit_transform(X_test, y_test)\n",
    "\n",
    "            x = pca_3d[:, 0]\n",
    "            y = pca_3d[:, 1]\n",
    "            z = pca_3d[:, 2]\n",
    "\n",
    "            plot_3d(x, y, z, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e2313",
   "metadata": {},
   "source": [
    "Данная функция печатает метки для различных значений отбора признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66bb5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def print_with_selection_features(model=tree.DecisionTreeClassifier, init_parameters={}, custom_fit_predict=None, **parameters):\n",
    "    if custom_fit_predict:\n",
    "        fit_predict = custom_fit_predict\n",
    "    %time fit_predict(X_train_transform, X_test_transform, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f0c11",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764ac82",
   "metadata": {},
   "source": [
    "# Формула Байеса\n",
    "\n",
    "Формула Байеса позволяет «переставить причину и следствие»: по известному факту события вычислить вероятность того, что оно было вызвано данной причиной. События, отражающие действие «причин», в данном случае называют гипотезами, так как они — предполагаемые события, повлекшие данное.\n",
    "\n",
    "$P(A|B) =\\frac{P(A) \\cdot P(B | A)}{P(B)}$ (1)\n",
    "\n",
    "* $P(A)$  -- априорная вероятность гипотезы A;\n",
    "* $P(A|B)$ --  вероятность гипотезы A при наступлении события B (апостериорная вероятность);\n",
    "* $P(B|A)$ --  вероятность наступления события B при истинности гипотезы A;\n",
    "* $P(B)$ -- полная вероятность наступления события B.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13a2c2",
   "metadata": {},
   "source": [
    "## Случай с одним признаком\n",
    "\n",
    "Для классифкации на основе одного признака формулу (1) мы можем переписать следующим образом (2):\n",
    "\n",
    "$P(class|feature) =\\frac{P(class) \\cdot P(feature | class)}{P(feature)}$ (2)\n",
    "\n",
    "Различие между теоремой Байеса и наивным классификатором Байеса состоит в том, что наивный классификатор предполагает условную независимость, тогда как теорема Байеса ее не предполагает. Это означает, что между всеми входными свойствами классификатора нет взаимозависимости. \n",
    "\n",
    "Возможно это не очень удачное предположение, но именно поэтому этот алгоритм называют «наивным» (naive). В этом также одна из причин ускоренной работы алгоритма. Несмотря на то, что алгоритм «наивен», он все же может превзойти сложные модели. Поэтому не позволяйте названию вводить вас в заблуждение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adcaf775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>stroll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>солнечно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>снег</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>облачно</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>дождь</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>солнечно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>снег</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>облачно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>снег</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>солнечно</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>облачно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>снег</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>солнечно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>дождь</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>дождь</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>облачно</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weather  stroll\n",
       "0   солнечно    True\n",
       "1       снег   False\n",
       "2    облачно   False\n",
       "3      дождь   False\n",
       "4   солнечно    True\n",
       "5       снег   False\n",
       "6    облачно    True\n",
       "7       снег   False\n",
       "8   солнечно   False\n",
       "9    облачно    True\n",
       "10      снег    True\n",
       "11  солнечно    True\n",
       "12     дождь   False\n",
       "13     дождь    True\n",
       "14   облачно    True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "        ('солнечно', True),\n",
    "        ('снег', False),\n",
    "        ('облачно', False),\n",
    "        ('дождь', False),\n",
    "        ('солнечно', True),\n",
    "        ('снег', False),\n",
    "        ('облачно', True),\n",
    "        ('снег', False),\n",
    "        ('солнечно', False),\n",
    "        ('облачно', True),\n",
    "        ('снег', True),\n",
    "        ('солнечно', True),\n",
    "        ('дождь', False),\n",
    "        ('дождь', True),\n",
    "        ('облачно', True),\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['weather', 'stroll'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36b9c8",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Какова вероятность отправиться на прогулку если идёт дождь, при наличии следующих наблюдений?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc9940",
   "metadata": {},
   "source": [
    "Общая формула будет выглядеть так: $p(stroll|weather)=\\frac{p(stroll)*p(weather|stroll)}{p(weather)}$\n",
    "Применительно к конкретным значениям: $p(yes|rainy)=\\frac{p(yes)*p(rainy|yes)}{p(rainy)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3eea4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_rainy = len(df.loc[df.weather == 'дождь']) / len(df)\n",
    "p_stroll = len(df.loc[df.stroll == True]) / len(df)\n",
    "p_rainy_if_stroll = len(df.loc[(df.stroll == True) & (df.weather == 'дождь')]) / len(df.loc[df.stroll == True])\n",
    "\n",
    "p_stroll_if_rainy = p_stroll * p_rainy_if_stroll / p_rainy\n",
    "p_stroll_if_rainy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76019986",
   "metadata": {},
   "source": [
    "## Случай с несколькими дискретными признаками\n",
    "\n",
    "\n",
    "В теореме Байеса вы должны вычислить единую условную вероятность с учетом всех свойств (вверху). С помощью наивного классификатора Байеса мы все упрощаем, вычисляя для каждого свойства условную вероятность, а затем перемножая их. Именно поэтому он и называется «наивным», поскольку условные вероятности всех свойств вычисляются независимо друг от друга.\n",
    "\n",
    "Теорема Байеса:\n",
    "\n",
    "$P(class | x_1, x_2, \\dots, x_n) = \\frac{P(x_1, x_2, \\dots, x_n | class) \\cdot P(A)}{P(x_1, x_2, \\dots, x_n)}$ (5)\n",
    "\n",
    "Naive Bayes:\n",
    "\n",
    "$P(class | x_1, x_2, \\dots, x_n) = p(class) \\cdot P(x_1|class) \\cdot P(x_2|class) \\cdot ... \\cdot P(x_n|class)$ (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f52d3",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Разбить свои данные на тренировочную и тестовую выборку.\n",
    "На основе обучающей создать модель наивного байеса, используя предложенное выше соотношение (6).\n",
    "\n",
    "На тестовой выборке посчитать accuracy, precision и recall.\n",
    "\n",
    "Если в данных содержатся числовые признаки, то разбейти их на квартили (границы: 25%, 50%, 75%  -- получится 4 бинарных признака)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cb4440d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([2, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 1, 3])\n",
    "np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c905dc",
   "metadata": {},
   "source": [
    "# Случай с числовыми признаками\n",
    "\n",
    "Перед построением частотных таблиц числовые переменные можно преобразовать в их категориальные аналоги (разбиение). Другой вариант -- использовать распределение числовой переменной, чтобы иметь представление о её частоте. Например, одна из распространенных практик - предполагать нормальные распределения для числовых переменных.\n",
    " \n",
    "Функция плотности вероятности для нормального распределения определяется двумя параметрами (средним значением и стандартным отклонением).\n",
    "\n",
    "$\\mu = \\frac{1}{n}\\sum\\limits_{i=1}^{n} x_i$ -- среднее\n",
    "\n",
    "$\\sigma = \\left[ \\frac{1}{n-1} \\sum\\limits_{i=1}^{n} (x_i - \\mu)^2 \\right]^{0.5}$ -- стандартное отклонение\n",
    "\n",
    "$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i — \\mu_y)^2}{2\\sigma^2_y}\\right)$ -- функция плотности для нормального распределения\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266a071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, is_continuous=True, quartile=4):\n",
    "        self.is_continuous = is_continuous\n",
    "        if self.is_continuous:\n",
    "            self.mu = {}\n",
    "            self.sigma = {}\n",
    "        else:\n",
    "            self.quartile = int(quartile)\n",
    "            self.values_quartile = {}\n",
    "            self.prob_quartile = {}\n",
    "        self.classes = [0, 1]\n",
    "        self.prob_classes = [0.5, 0.5]\n",
    "    \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        if self.is_continuous:\n",
    "            self.mu = {}\n",
    "            self.sigma = {}\n",
    "        else:\n",
    "            self.values_quartile = {}\n",
    "            self.prob_quartile = {}\n",
    "        classes, count_classes = np.unique(y, return_counts=True)\n",
    "        self.classes = classes\n",
    "        self.prob_classes = count_classes / len(y)\n",
    "        for num_column in range(X.shape[1]):\n",
    "            self.bayes_one_column_fit(num_column, X[:, num_column], y)\n",
    "        if verbose and self.is_continuous:\n",
    "            print(self.mu)\n",
    "            print(self.sigma)\n",
    "    \n",
    "    def find_min_max(self, column):\n",
    "        return column.min(), (column.max() - column.min()) / self.quartile\n",
    "    \n",
    "    def bayes_one_column_fit(self, name_column, column, y):\n",
    "        column = column.astype(\"float\")\n",
    "        if self.is_continuous:\n",
    "            mu_values = []\n",
    "            sigma_values = []\n",
    "            for y_class in self.classes:\n",
    "                column_y_i = column[np.where(y == y_class)]\n",
    "                mu_values.append(column_y_i.mean())\n",
    "                sigma_values.append(column_y_i.std())\n",
    "            self.mu[name_column] = mu_values\n",
    "            self.sigma[name_column] = sigma_values\n",
    "        else:\n",
    "            min_val, step = self.find_min_max(column)\n",
    "            vals_quartiles = [min_val + step * i for i in range(1, self.quartile)]\n",
    "            self.values_quartile[name_column] = vals_quartiles\n",
    "            prob_values = []\n",
    "            for y_class in self.classes:\n",
    "                column_y_i = column[np.where(y == y_class)]\n",
    "                prev_vals = 0\n",
    "                prob_values_y_i = []\n",
    "                for val_quartile in vals_quartiles:\n",
    "                    cur_vals = len(column_y_i[np.where(column_y_i <= val_quartile)])\n",
    "                    prob_values_y_i.append((cur_vals - prev_vals) / len(column_y_i))\n",
    "                    prev_vals = cur_vals\n",
    "                prob_values_y_i.append((len(column_y_i) - prev_vals) / len(column_y_i))\n",
    "                prob_values.append(prob_values_y_i)\n",
    "            self.prob_quartile[name_column] = prob_values\n",
    "    \n",
    "    def density_func(self, x, mu, sigma, eps=1.0e-3):\n",
    "        return np.exp(-np.power(x - mu, 2) / (2 * sigma * sigma + eps)) / np.sqrt(2. * np.pi * sigma * sigma + eps)\n",
    "    \n",
    "    def get_p_x_i(self, x, y_i):\n",
    "        x = x.astype(\"float\")\n",
    "        for num_column in range(x.shape[0]):\n",
    "            p_x_i = 1.\n",
    "            if self.is_continuous:\n",
    "                pass\n",
    "            else:\n",
    "                idx_x = 0\n",
    "                for quartile in self.values_quartile[num_column]:\n",
    "                    if x[num_column] < quartile:\n",
    "                        break\n",
    "                    else:\n",
    "                        idx_x += 1\n",
    "            if self.is_continuous:\n",
    "                p_x_i *= self.density_func(x[num_column], self.mu[num_column][y_i], self.sigma[num_column][y_i])\n",
    "            else:\n",
    "                p_x_i *= self.prob_quartile[num_column][np.where(self.classes == y_i)[0][0]][idx_x]\n",
    "        return p_x_i\n",
    "                \n",
    "    # P(class | x1...xn) = P(class) * P(x1|class) * ... * P(xn|class)\n",
    "    def predict(self, X):\n",
    "        return [\n",
    "                self.classes[np.argmax([prob_class * self.get_p_x_i(x, y_i) for y_i, prob_class in zip(self.classes, self.prob_classes)])] \n",
    "            for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8dec1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.fit(X_train_transform, y_train)\n",
    "y_pred_CNB = nb.predict(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aecf4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naive_bayes.GaussianNB()\n",
    "nb.fit(X_train_transform, y_train)\n",
    "y_pred_GNB = nb.predict(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54d0e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[921  11]\n",
      " [872  52]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.68       932\n",
      "           1       0.83      0.06      0.11       924\n",
      "\n",
      "    accuracy                           0.52      1856\n",
      "   macro avg       0.67      0.52      0.39      1856\n",
      "weighted avg       0.67      0.52      0.39      1856\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[792 140]\n",
      " [395 529]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75       932\n",
      "           1       0.79      0.57      0.66       924\n",
      "\n",
      "    accuracy                           0.71      1856\n",
      "   macro avg       0.73      0.71      0.71      1856\n",
      "weighted avg       0.73      0.71      0.71      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_test_transform, y_test, y_pred_CNB)\n",
    "print()\n",
    "print_metrics(X_test_transform, y_test, y_pred_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d7a5953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_1 = np.array([[0], [1], [0]])\n",
    "y_1 = np.array([0, 1, 1])\n",
    "X_2 = np.array([[0], [1]])\n",
    "nb_2 = NaiveBayes(quartile=2)\n",
    "nb_2.fit(X_1, y_1)\n",
    "y_pred_CNB_1 = nb_2.predict(X_2)\n",
    "\n",
    "nb_2_G = naive_bayes.GaussianNB()\n",
    "nb_2_G.fit(X_1, y_1)\n",
    "y_pred_GNB_1 = nb_2_G.predict(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "756a09b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_2, np.array([0, 1]), y_pred_CNB_1)\n",
    "print()\n",
    "print_metrics(X_2, np.array([0, 1]), y_pred_GNB_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23076c3f",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fb53b",
   "metadata": {},
   "source": [
    "В данной работе мы реализовали алгоритм Наивного Байесса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
