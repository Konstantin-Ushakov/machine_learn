{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54d6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92b202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "from sklearn import tree, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d9e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ab15b",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467833",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7277957",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9412d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank_additional_preprocessed.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fa3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>previous_0</th>\n",
       "      <th>previous_1</th>\n",
       "      <th>previous_2</th>\n",
       "      <th>previous_3</th>\n",
       "      <th>previous_4</th>\n",
       "      <th>previous_5</th>\n",
       "      <th>previous_6</th>\n",
       "      <th>previous_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  campaign  pdays  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0       56         1    999           1.1          93.994          -36.4   \n",
       "1       57         1    999           1.1          93.994          -36.4   \n",
       "2       37         1    999           1.1          93.994          -36.4   \n",
       "3       40         1    999           1.1          93.994          -36.4   \n",
       "4       56         1    999           1.1          93.994          -36.4   \n",
       "...    ...       ...    ...           ...             ...            ...   \n",
       "41183   73         1    999          -1.1          94.767          -50.8   \n",
       "41184   46         1    999          -1.1          94.767          -50.8   \n",
       "41185   56         2    999          -1.1          94.767          -50.8   \n",
       "41186   44         1    999          -1.1          94.767          -50.8   \n",
       "41187   74         3    999          -1.1          94.767          -50.8   \n",
       "\n",
       "       euribor3m  nr.employed  y  job_admin.  ...  poutcome_nonexistent  \\\n",
       "0          4.857       5191.0  0           0  ...                     1   \n",
       "1          4.857       5191.0  0           0  ...                     1   \n",
       "2          4.857       5191.0  0           0  ...                     1   \n",
       "3          4.857       5191.0  0           1  ...                     1   \n",
       "4          4.857       5191.0  0           0  ...                     1   \n",
       "...          ...          ... ..         ...  ...                   ...   \n",
       "41183      1.028       4963.6  1           0  ...                     1   \n",
       "41184      1.028       4963.6  0           0  ...                     1   \n",
       "41185      1.028       4963.6  0           0  ...                     1   \n",
       "41186      1.028       4963.6  1           0  ...                     1   \n",
       "41187      1.028       4963.6  0           0  ...                     0   \n",
       "\n",
       "       poutcome_success  previous_0  previous_1  previous_2  previous_3  \\\n",
       "0                     0           1           0           0           0   \n",
       "1                     0           1           0           0           0   \n",
       "2                     0           1           0           0           0   \n",
       "3                     0           1           0           0           0   \n",
       "4                     0           1           0           0           0   \n",
       "...                 ...         ...         ...         ...         ...   \n",
       "41183                 0           1           0           0           0   \n",
       "41184                 0           1           0           0           0   \n",
       "41185                 0           1           0           0           0   \n",
       "41186                 0           1           0           0           0   \n",
       "41187                 0           0           1           0           0   \n",
       "\n",
       "       previous_4  previous_5  previous_6  previous_7  \n",
       "0               0           0           0           0  \n",
       "1               0           0           0           0  \n",
       "2               0           0           0           0  \n",
       "3               0           0           0           0  \n",
       "4               0           0           0           0  \n",
       "...           ...         ...         ...         ...  \n",
       "41183           0           0           0           0  \n",
       "41184           0           0           0           0  \n",
       "41185           0           0           0           0  \n",
       "41186           0           0           0           0  \n",
       "41187           0           0           0           0  \n",
       "\n",
       "[41188 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f37df4",
   "metadata": {},
   "source": [
    "Посмотрим на сбалансированность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3dc5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([36548,  4640], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, samples = np.unique(df.y, return_counts=True)\n",
    "labels, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682d222",
   "metadata": {},
   "source": [
    "Как мы видим, данные несбалансированы: данных класса 0 приблизительно в 10 раз больше, чем данных класса 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89256fbe",
   "metadata": {},
   "source": [
    "При таком дисбалансе при downsampling потеряется большое число информации, поэтому выполним upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62dd446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET i: 4640\n",
      "GET i: 9280\n",
      "GET i: 13920\n",
      "GET i: 18560\n",
      "GET i: 23200\n",
      "GET i: 27840\n",
      "GET i: 32480\n",
      "GET samples: 36548 label 0, 36548 label 1\n",
      "Make shuffle dataframe\n"
     ]
    }
   ],
   "source": [
    "df_0 = df.loc[df.y == 0].reset_index()\n",
    "df_1_copy = df.loc[df.y == 1].reset_index()\n",
    "df_1 = df.loc[df.y == 1].reset_index()\n",
    "\n",
    "i = len(df_1_copy)\n",
    "while i < len(df_0):\n",
    "    print('GET i: {}'.format(i))\n",
    "    if i + len(df_1_copy) < len(df_0):\n",
    "        df_1 = df_1.append(df_1_copy)\n",
    "        i += len(df_1_copy)\n",
    "    else:\n",
    "        df_1 = df_1.append(df_1_copy.loc[i % len(df_1_copy) : (len(df_0) - 1) % len(df_1_copy)])\n",
    "        i = len(df_1)\n",
    "\n",
    "print('GET samples: {} label 0, {} label 1'.format(len(df_0), len(df_1)))\n",
    "df_sample = pd.concat([df_0, df_1], ignore_index=True).reset_index()\n",
    "print('Make shuffle dataframe')\n",
    "df_sample = df_sample.loc[np.random.permutation(len(df_sample))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d16130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73096, 71), (73096,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sample.drop('y', axis=1)\n",
    "y = df_sample.y\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b6181",
   "metadata": {},
   "source": [
    "Для удобства обработки разделим признаки на категориальные и вещественные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68df38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = np.array(['age', 'campaign', 'pdays', 'emp.var.rate', 'cons.price.idx', \n",
    "           'cons.conf.idx', 'euribor3m', 'nr.employed'])\n",
    "X_numeric = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194dcfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))\n",
    "X_categorical = X[categorical_cols]\n",
    "for col in categorical_cols:\n",
    "    X_categorical[col] = X_categorical[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96f7bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73096 entries, 34712 to 64201\n",
      "Data columns (total 63 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   default_yes                    73096 non-null  string\n",
      " 1   poutcome_failure               73096 non-null  string\n",
      " 2   month_jul                      73096 non-null  string\n",
      " 3   previous_4                     73096 non-null  string\n",
      " 4   job_blue-collar                73096 non-null  string\n",
      " 5   month_apr                      73096 non-null  string\n",
      " 6   day_of_week_wed                73096 non-null  string\n",
      " 7   previous_3                     73096 non-null  string\n",
      " 8   job_services                   73096 non-null  string\n",
      " 9   housing_unknown                73096 non-null  string\n",
      " 10  day_of_week_tue                73096 non-null  string\n",
      " 11  month_may                      73096 non-null  string\n",
      " 12  job_student                    73096 non-null  string\n",
      " 13  marital_married                73096 non-null  string\n",
      " 14  day_of_week_thu                73096 non-null  string\n",
      " 15  education_unknown              73096 non-null  string\n",
      " 16  contact_telephone              73096 non-null  string\n",
      " 17  marital_unknown                73096 non-null  string\n",
      " 18  level_0                        73096 non-null  string\n",
      " 19  previous_2                     73096 non-null  string\n",
      " 20  month_mar                      73096 non-null  string\n",
      " 21  month_oct                      73096 non-null  string\n",
      " 22  education_high.school          73096 non-null  string\n",
      " 23  loan_unknown                   73096 non-null  string\n",
      " 24  previous_7                     73096 non-null  string\n",
      " 25  education_basic.6y             73096 non-null  string\n",
      " 26  education_illiterate           73096 non-null  string\n",
      " 27  housing_no                     73096 non-null  string\n",
      " 28  month_sep                      73096 non-null  string\n",
      " 29  previous_0                     73096 non-null  string\n",
      " 30  job_retired                    73096 non-null  string\n",
      " 31  month_jun                      73096 non-null  string\n",
      " 32  previous_6                     73096 non-null  string\n",
      " 33  previous_1                     73096 non-null  string\n",
      " 34  education_basic.4y             73096 non-null  string\n",
      " 35  loan_yes                       73096 non-null  string\n",
      " 36  job_admin.                     73096 non-null  string\n",
      " 37  job_entrepreneur               73096 non-null  string\n",
      " 38  job_unemployed                 73096 non-null  string\n",
      " 39  loan_no                        73096 non-null  string\n",
      " 40  month_nov                      73096 non-null  string\n",
      " 41  previous_5                     73096 non-null  string\n",
      " 42  month_aug                      73096 non-null  string\n",
      " 43  default_unknown                73096 non-null  string\n",
      " 44  job_management                 73096 non-null  string\n",
      " 45  job_housemaid                  73096 non-null  string\n",
      " 46  month_dec                      73096 non-null  string\n",
      " 47  index                          73096 non-null  string\n",
      " 48  education_university.degree    73096 non-null  string\n",
      " 49  housing_yes                    73096 non-null  string\n",
      " 50  job_self-employed              73096 non-null  string\n",
      " 51  job_unknown                    73096 non-null  string\n",
      " 52  education_professional.course  73096 non-null  string\n",
      " 53  contact_cellular               73096 non-null  string\n",
      " 54  day_of_week_fri                73096 non-null  string\n",
      " 55  poutcome_success               73096 non-null  string\n",
      " 56  poutcome_nonexistent           73096 non-null  string\n",
      " 57  marital_divorced               73096 non-null  string\n",
      " 58  default_no                     73096 non-null  string\n",
      " 59  marital_single                 73096 non-null  string\n",
      " 60  education_basic.9y             73096 non-null  string\n",
      " 61  job_technician                 73096 non-null  string\n",
      " 62  day_of_week_mon                73096 non-null  string\n",
      "dtypes: string(63)\n",
      "memory usage: 35.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac747ba9",
   "metadata": {},
   "source": [
    "Разделим данные на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e523d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(X, X_categorical, X_numeric, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1f80d",
   "metadata": {},
   "source": [
    "Нормализируем значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f06a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_numeric)\n",
    "\n",
    "X_train_num_sc = scaler.transform(X_train_num)\n",
    "X_test_num_sc = scaler.transform(X_test_num)\n",
    "X_num_sc = scaler.transform(X_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a922c",
   "metadata": {},
   "source": [
    "Соединяем воедино все значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e01a2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = np.hstack((X_train_num_sc, X_train_cat))\n",
    "X_test_transform = np.hstack((X_test_num_sc, X_test_cat))\n",
    "X_transform = np.hstack((X_num_sc, X_categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b744b",
   "metadata": {},
   "source": [
    "Для некоторых алгоритмов введено условие неотрицательности, реализуем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71dd5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_transform)\n",
    "X_positive = scaler.transform(X_transform)\n",
    "X_train_positive = scaler.transform(X_train_transform)\n",
    "X_test_positive = scaler.transform(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138c1f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18518519, 0.        , 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.18518519, 0.14545455, 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.25925926, 0.01818182, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.2345679 , 0.03636364, 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.62962963, 0.01818182, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.20987654, 0.        , 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f086cf3",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523321e",
   "metadata": {},
   "source": [
    "### 1. Одномерный отбор признаков\n",
    "\n",
    "Признаки, имеющие наиболее выраженную взаимосвязь с целевой переменной, могут быть отобраны с помощью статистических критериев. Библиотека scikit-learn содержит класс [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest), реализующий одномерный отбор признаков (univariate feature selection). Этот класс можно применять совместно с различными статистическими критериями для отбора заданного количества признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4e2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.148e+00 8.262e+01 7.183e+02 2.867e+03 3.906e+02 4.998e+01 4.929e+03\n",
      " 2.506e+03 3.000e+00 1.412e+02 1.904e+02 2.010e+02 9.170e+02 7.688e+02\n",
      " 5.314e+00 7.207e+02 1.916e+02 1.341e+00 9.854e+00 1.682e+03 8.672e+02\n",
      " 1.394e+02 2.546e+01 6.854e+01 3.126e+03 4.780e+00 9.137e+03 1.679e+03\n",
      " 1.516e+03 1.448e+03 7.414e+00 1.341e+00 1.000e+00 1.038e+02 7.043e+00\n",
      " 1.242e+01 1.134e+03 9.762e+02 9.432e+02 8.923e+00 1.570e+01 1.418e+03\n",
      " 2.040e+01 3.026e+00 1.255e+02 5.197e+01 3.380e+01 8.754e-01 2.476e+01\n",
      " 8.298e+01 1.526e+01 1.825e+03 9.450e-03 7.916e+00 4.760e+02 2.107e+03\n",
      " 2.957e+02 1.205e+01 3.009e+00 1.544e-02 2.416e-02 1.219e+03 7.085e+00\n",
      " 5.562e+03 9.762e+02 1.950e+01 3.479e+02 3.440e+02 3.553e+02 6.626e+00\n",
      " 6.719e+01]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X_positive, y)\n",
    "\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "X_train_k_best = fit.transform(X_train_positive)\n",
    "X_test_k_best = fit.transform(X_test_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883f7be",
   "metadata": {},
   "source": [
    "### 2. Рекурсивное исключение признаков\n",
    "\n",
    "Метод рекурсивного исключения признаков (recursive feature elimination, RFE) реализует следующий алгоритм: модель обучается на исходном наборе признаков и оценивает их значимость, затем исключается один или несколько наименее значимых признаков, модель обучается на оставшихся признаках, и так далее, пока не останется заданное количество лучших признаков. В документации scikit-learn вы можете подробнее прочитать о классе [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE).\n",
    "\n",
    "В примере ниже метод RFE применяется в сочетании с логистической регрессией для отбора 4-х лучших признаков. Для совместного использования с RFE можно выбирать различные модели, важно лишь, чтобы они были достаточно эффективны и совместимы с RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd4ca2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 4\n",
      "Selected Features: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True]\n",
      "Feature Ranking: [68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45\n",
      " 44 43  1 13 12 11 10  9  8  7 15 17 19 21 23 25 27 29 31 33 35 37 39 41\n",
      " 42 40 38 36 34 32 30 28 26 24 22 20 18 16 14  6  5  4  3  2  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "test = RFE(tree.DecisionTreeClassifier(), n_features_to_select=4)\n",
    "fit = test.fit(X_transform, y)\n",
    "\n",
    "# summarize scores\n",
    "print('Num features: {}'.format(fit.n_features_))\n",
    "print('Selected Features: {}'.format(fit.support_))\n",
    "print('Feature Ranking: {}'.format(fit.ranking_))\n",
    "X_train_recursive_dtc = fit.transform(X_train_positive)\n",
    "X_test_recursive_dtc = fit.transform(X_test_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25ff31",
   "metadata": {},
   "source": [
    "### 3. Метод главных компонент\n",
    "\n",
    "Метод главных компонент (principal component analysis, PCA) позволяет уменьшить размерность данных с помощью преобразования на основе линейной алгебры. Пользователь может задать требуемое количество измерений (главных компонент) в результирующих данных.\n",
    "\n",
    "В примере ниже мы выделяем 3 главных компоненты с помощью PCA.\n",
    "\n",
    "Подробная информация о классе [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) доступна в документации scikit-learn. Если вас заинтересовала математика PCA, обратитесь к статье в [Википедии](https://en.wikipedia.org/wiki/Principal_component_analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca39093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "test = PCA(n_components=4)\n",
    "fit = test.fit(X_transform, y)\n",
    "\n",
    "X_train_pca = fit.transform(X_train_positive)\n",
    "X_test_pca = fit.transform(X_test_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96d406",
   "metadata": {},
   "source": [
    "### 4. Отбор на основе важности признаков\n",
    "\n",
    "Ансамблевые алгоритмы на основе деревьев решений, такие как случайный лес (random forest), позволяют оценить важность признаков.\n",
    "\n",
    "В представленном ниже примере мы обучаем классификатор ExtraTreesClassifier, чтобы с его помощью определить важность признаков. Подробнее о классе [ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) можно узнать из документации scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015899a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.802e-02 1.400e-02 1.255e-02 2.646e-02 9.902e-03 8.928e-03 6.018e-02\n",
      " 3.975e-02 4.933e-07 3.438e-03 2.409e-03 1.941e-04 4.655e-03 3.143e-03\n",
      " 4.138e-03 4.887e-04 2.966e-03 9.455e-04 4.234e-03 1.380e-02 2.016e-03\n",
      " 5.089e-03 4.545e-03 2.202e-03 7.858e-03 3.004e-04 5.549e-01 1.465e-03\n",
      " 3.690e-03 4.468e-03 4.639e-03 9.256e-04 2.938e-05 2.278e-03 7.334e-05\n",
      " 5.605e-03 1.218e-03 7.763e-03 3.122e-03 2.631e-03 1.793e-05 2.031e-03\n",
      " 2.689e-03 4.191e-03 4.690e-03 1.940e-03 1.517e-03 4.167e-03 2.607e-03\n",
      " 5.367e-05 2.063e-03 4.195e-03 2.754e-03 1.563e-03 5.700e-04 4.301e-02\n",
      " 4.915e-03 5.633e-03 2.042e-03 8.498e-04 3.302e-03 8.039e-03 4.572e-03\n",
      " 1.304e-02 8.048e-03 3.431e-03 5.654e-03 4.697e-03 3.804e-03 3.994e-03\n",
      " 4.902e-03]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "test = ExtraTreesClassifier()\n",
    "fit = test.fit(X_transform, y)\n",
    "print(fit.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb641f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54822, 71), (71,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.1\n",
    "important = fit.feature_importances_ > eps\n",
    "X_train_positive.shape, important.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2704d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccf6d00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54822, 1), (54822, 71))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_etc = X_train_positive[:, important]\n",
    "X_test_etc = X_test_positive[:, important]\n",
    "X_train_etc.shape, X_train_positive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6aeef",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45784d",
   "metadata": {},
   "source": [
    "Напишем методы, которые будут обучать модель и предсказывать результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5802af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, is_classification=True):\n",
    "    if is_classification:\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b10bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X_train, X_test, y_train, y_test, \n",
    "                model=tree.DecisionTreeClassifier, init_parameters={}, \n",
    "                verbose=True, **parameters):\n",
    "    print('Start fit model and predict values')\n",
    "    classifier_model = model(**init_parameters)\n",
    "\n",
    "    clf_model = GridSearchCV(classifier_model, parameters)\n",
    "    clf_model.fit(X_train, y_train)\n",
    "    # Get best model\n",
    "    best_est = clf_model.best_estimator_\n",
    "    if verbose:\n",
    "        print('GridSearchCV: best estimator:\\n{},\\nwith best parameters:\\n{}'.format(clf_model.best_estimator_, clf_model.best_params_))\n",
    "    # Predict value\n",
    "    y_pred = best_est.predict(X_test)\n",
    "    if verbose:\n",
    "        print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66bb5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def print_with_selection_features(model=tree.DecisionTreeClassifier, init_parameters={}, **parameters):\n",
    "    print('Начинаем сравнение разных методов отбора признаков.')\n",
    "    print()\n",
    "    print('Без отбора признаков')\n",
    "    %time fit_predict(X_train_transform, X_test_transform, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)\n",
    "    print()\n",
    "    print('Одномерный отбор признаков')\n",
    "    %time fit_predict(X_train_k_best, X_test_k_best, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)\n",
    "    print()\n",
    "    print('Рекурсивное исключение признаков')\n",
    "    %time fit_predict(X_train_recursive_dtc, X_test_recursive_dtc, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)\n",
    "    print()\n",
    "    print('Метод главных компонент')\n",
    "    %time fit_predict(X_train_pca, X_test_pca, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)\n",
    "    print()\n",
    "    print('Отбор на основе важности признаков')\n",
    "    %time fit_predict(X_train_etc, X_test_etc, y_train, y_test, model=model, init_parameters=init_parameters, **parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000c3c8",
   "metadata": {},
   "source": [
    "## [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b598b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dtc = {\n",
    "    'max_depth': [1, 3, 5, 10, 30],\n",
    "    'min_samples_split': [2, 3, 5, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba235678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем сравнение разных методов отбора признаков.\n",
      "\n",
      "Без отбора признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "DecisionTreeClassifier(max_depth=1),\n",
      "with best parameters:\n",
      "{'max_depth': 1, 'min_samples_split': 2}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 1min 55s\n",
      "\n",
      "Одномерный отбор признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "DecisionTreeClassifier(max_depth=1),\n",
      "with best parameters:\n",
      "{'max_depth': 1, 'min_samples_split': 2}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 1.34 s\n",
      "\n",
      "Рекурсивное исключение признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "DecisionTreeClassifier(max_depth=1),\n",
      "with best parameters:\n",
      "{'max_depth': 1, 'min_samples_split': 2}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 1.23 s\n",
      "\n",
      "Метод главных компонент\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "DecisionTreeClassifier(max_depth=10),\n",
      "with best parameters:\n",
      "{'max_depth': 10, 'min_samples_split': 2}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 4.69 s\n",
      "\n",
      "Отбор на основе важности признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "DecisionTreeClassifier(max_depth=1),\n",
      "with best parameters:\n",
      "{'max_depth': 1, 'min_samples_split': 2}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "print_with_selection_features(model=tree.DecisionTreeClassifier, **parameters_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b92df4",
   "metadata": {},
   "source": [
    "Алгоритм работает идеально.\n",
    "\n",
    "Попробуем взять другой алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fd82b",
   "metadata": {},
   "source": [
    "## [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "\n",
    "Naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02493ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_nb = {\n",
    "    'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-5, 1e-2, 1e-1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1a4a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем сравнение разных методов отбора признаков.\n",
      "\n",
      "Без отбора признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "GaussianNB(var_smoothing=100),\n",
      "with best parameters:\n",
      "{'var_smoothing': 100}\n",
      "[[8721  387]\n",
      " [ 498 8668]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      9108\n",
      "           1       0.96      0.95      0.95      9166\n",
      "\n",
      "    accuracy                           0.95     18274\n",
      "   macro avg       0.95      0.95      0.95     18274\n",
      "weighted avg       0.95      0.95      0.95     18274\n",
      "\n",
      "Wall time: 50.9 s\n",
      "\n",
      "Одномерный отбор признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "GaussianNB(var_smoothing=1e-10),\n",
      "with best parameters:\n",
      "{'var_smoothing': 1e-10}\n",
      "[[8733  375]\n",
      " [ 776 8390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      9108\n",
      "           1       0.96      0.92      0.94      9166\n",
      "\n",
      "    accuracy                           0.94     18274\n",
      "   macro avg       0.94      0.94      0.94     18274\n",
      "weighted avg       0.94      0.94      0.94     18274\n",
      "\n",
      "Wall time: 534 ms\n",
      "\n",
      "Рекурсивное исключение признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "GaussianNB(var_smoothing=1e-10),\n",
      "with best parameters:\n",
      "{'var_smoothing': 1e-10}\n",
      "[[8967  141]\n",
      " [ 126 9040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      9108\n",
      "           1       0.98      0.99      0.99      9166\n",
      "\n",
      "    accuracy                           0.99     18274\n",
      "   macro avg       0.99      0.99      0.99     18274\n",
      "weighted avg       0.99      0.99      0.99     18274\n",
      "\n",
      "Wall time: 538 ms\n",
      "\n",
      "Метод главных компонент\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "GaussianNB(var_smoothing=1e-10),\n",
      "with best parameters:\n",
      "{'var_smoothing': 1e-10}\n",
      "[[8159  949]\n",
      " [1432 7734]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      9108\n",
      "           1       0.89      0.84      0.87      9166\n",
      "\n",
      "    accuracy                           0.87     18274\n",
      "   macro avg       0.87      0.87      0.87     18274\n",
      "weighted avg       0.87      0.87      0.87     18274\n",
      "\n",
      "Wall time: 528 ms\n",
      "\n",
      "Отбор на основе важности признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "GaussianNB(var_smoothing=0.1),\n",
      "with best parameters:\n",
      "{'var_smoothing': 0.1}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "print_with_selection_features(model=naive_bayes.GaussianNB, **parameters_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d354b",
   "metadata": {},
   "source": [
    "На данной моделе хорошо видно, что разные виды отборов приносят разные результаты.\n",
    "\n",
    "В данной задаче отработали (по убыванию точности):\n",
    "1. Отбор на основе важности признаков (100% точность)\n",
    "1. Рекурсивное исключение признаков (Уменьшает число ошибок как в классе 1, так и в классе 0)\n",
    "1. Без отбора\n",
    "1. Одномерный отбор признаков (Сильно ошибается с классом 1, присваивая его классу 0, в классе 0 ошибок приблизительно так же, как если бы отбора не было)\n",
    "1. Метод главных компонент (Очень много ошибок как в классе 0, так и в классе 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9c58a",
   "metadata": {},
   "source": [
    "## [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5152917",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = {\n",
    "    'class_weight': ['balanced'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbd69f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем сравнение разных методов отбора признаков.\n",
      "\n",
      "Без отбора признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear'),\n",
      "with best parameters:\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 1min 56s\n",
      "\n",
      "Одномерный отбор признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear'),\n",
      "with best parameters:\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 9.27 s\n",
      "\n",
      "Рекурсивное исключение признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='saga'),\n",
      "with best parameters:\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "[[9105    3]\n",
      " [   4 9162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 8.3 s\n",
      "\n",
      "Метод главных компонент\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='saga'),\n",
      "with best parameters:\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "[[7838 1270]\n",
      " [5357 3809]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70      9108\n",
      "           1       0.75      0.42      0.53      9166\n",
      "\n",
      "    accuracy                           0.64     18274\n",
      "   macro avg       0.67      0.64      0.62     18274\n",
      "weighted avg       0.67      0.64      0.62     18274\n",
      "\n",
      "Wall time: 17.4 s\n",
      "\n",
      "Отбор на основе важности признаков\n",
      "Start fit model and predict values\n",
      "GridSearchCV: best estimator:\n",
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='saga'),\n",
      "with best parameters:\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "[[9108    0]\n",
      " [   0 9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9108\n",
      "           1       1.00      1.00      1.00      9166\n",
      "\n",
      "    accuracy                           1.00     18274\n",
      "   macro avg       1.00      1.00      1.00     18274\n",
      "weighted avg       1.00      1.00      1.00     18274\n",
      "\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "print_with_selection_features(model=LogisticRegression, **parameters_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ad177",
   "metadata": {},
   "source": [
    "Получаем очень интересные результаты.\n",
    "\n",
    "Без отбора признаков, Одномерный отбор признаков и Отбор на основе важности признаков проявили точность 100%.\n",
    "\n",
    "Рекурсивное исключение признаков практически не ошибается, но имеется мизерное число ошибок.\n",
    "\n",
    "Метод главных компонент отработал ужасно на данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23076c3f",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fb53b",
   "metadata": {},
   "source": [
    "В данной работе мы разобрались с методами отбора признаков, рассмотрели некоторые из них и сравнили их между собой на своих данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
