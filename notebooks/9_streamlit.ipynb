{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучение и тест, нормализуем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache\n",
    "def prepared_dataset(df, random_state=None):\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df.price.astype('int64')\n",
    "    numeric_cols = np.array(['symboling', 'normalized_losses', 'wheel_base', 'length', 'width',\n",
    "       'height', 'curb_weight', 'num_of_cylinders', 'engine_size', 'bore',\n",
    "       'stroke', 'compression_ratio', 'horsepower', 'peak_rpm', 'city_mpg',\n",
    "       'highway_mpg'])\n",
    "    X_numeric = X[numeric_cols]\n",
    "    categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))\n",
    "    X_categorical = X[categorical_cols]\n",
    "    for col in categorical_cols:\n",
    "        X_categorical[col] = X_categorical[col].astype('string')\n",
    "    # Разделим на обучение и тест\n",
    "    X_train, X_test, X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(X, X_categorical, X_numeric, y, test_size=0.15, random_state=random_state)\n",
    "    # Номализуем значения\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_num)\n",
    "\n",
    "    X_train_num_sc = scaler.transform(X_train_num)\n",
    "    X_test_num_sc = scaler.transform(X_test_num)\n",
    "    # Соединяем значения воедино\n",
    "    X_train_transform = np.hstack((X_train_num_sc, X_train_cat))\n",
    "    X_test_transform = np.hstack((X_test_num_sc, X_test_cat))\n",
    "    return X_train_transform, y_train, X_test_transform, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainee_model(X_train, y_train, parameters={\n",
    "    'alpha': 1,\n",
    "    'fit_intercept': True,\n",
    "    'max_iter': 1,\n",
    "    'positive': True\n",
    "}):\n",
    "    classifier_EN = ElasticNet(alpha=parameters['alpha'], fit_intercept=parameters['fit_intercept'],\n",
    "                               max_iter=parameters['max_iter'], positive=parameters['positive'])\n",
    "    classifier_EN.fit(X_train, y_train)\n",
    "    return classifier_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prediction(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    st.write('R^2: {}'.format(r2_score(y_test, y_pred)))\n",
    "    st.write('MSE: {}'.format(mean_squared_error(y_test, y_pred)))\n",
    "    st.write('RMSE: {}'.format(mean_squared_error(y_test, y_pred, squared=False)))\n",
    "    st.write('MAE: {}'.format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сериализация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_model(model):\n",
    "    return pickle.dumps(model)\n",
    "\n",
    "def deserialize_model(bin_data):\n",
    "    return pickle.loads(bin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сериализации/десериализации в/из файла можно использовать следующие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_model_file(model, filename=\"ser.dat\"):\n",
    "    with open(filename, 'wb') as fin:\n",
    "        pickle.dump(model, fin)\n",
    "    return filename\n",
    "\n",
    "def deserialize_model(filename=\"ser.dat\"):\n",
    "    with open(filename, 'rb') as fout:\n",
    "        model = pickle.load(fout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [STREAMLIT](https://www.notion.so/a53e9e35dc4f482f889e2a3f516be9fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache\n",
    "def load_data(filename='../data/automobile_preprocessed.csv'):\n",
    "    df = pd.read_csv(filename, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    page = st.sidebar.selectbox('Choose a page', ['Description', 'Regressor'])\n",
    "    \n",
    "    if page == 'Description':\n",
    "        st.header('Automobile dataset description')\n",
    "        description_task = '''## Task 3\n",
    "Подготовьте данные, уберите аномалии. Разбейте датасет, проведите обучение моделей: \n",
    "- Линейная регрессия;\n",
    "- Регрессия дерева решений;\n",
    "- LASSO;\n",
    "- Гребневая регрессия;\n",
    "- Elastic Net регрессия.\n",
    "\n",
    "Найдите реализации методов в sklearn, оставьте в нотбуке ссылки на документацию. Найдите наилучшие гиперпараметры. Оцените качество моделей: R2, Mean Square Error(MSE), Root Mean Square Error(RMSE),  mean absolute error (MAE). Свои действия снабжайте пояснениями.'''\n",
    "        st.write(description_task)\n",
    "        description = '''\n",
    "        ## Автомобили [Источник](https://archive.ics.uci.edu/ml/datasets/Automobile)\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "     Attribute:                Attribute Range:\n",
    "     ------------------        -----------------------------------------------\n",
    "  1. symboling:                -3, -2, -1, 0, 1, 2, 3.\n",
    "  2. normalized-losses:        continuous from 65 to 256.\n",
    "  3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n",
    "                               isuzu, jaguar, mazda, mercedes-benz, mercury,\n",
    "                               mitsubishi, nissan, peugot, plymouth, porsche,\n",
    "                               renault, saab, subaru, toyota, volkswagen, volvo\n",
    "  4. fuel-type:                diesel, gas.\n",
    "  5. aspiration:               std, turbo.\n",
    "  6. num-of-doors:             four, two.\n",
    "  7. body-style:               hardtop, wagon, sedan, hatchback, convertible.\n",
    "  8. drive-wheels:             4wd, fwd, rwd.\n",
    "  9. engine-location:          front, rear.\n",
    " 10. wheel-base:               continuous from 86.6 120.9.\n",
    " 11. length:                   continuous from 141.1 to 208.1.\n",
    " 12. width:                    continuous from 60.3 to 72.3.\n",
    " 13. height:                   continuous from 47.8 to 59.8.\n",
    " 14. curb-weight:              continuous from 1488 to 4066.\n",
    " 15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    " 16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n",
    " 17. engine-size:              continuous from 61 to 326.\n",
    " 18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    " 19. bore:                     continuous from 2.54 to 3.94.\n",
    " 20. stroke:                   continuous from 2.07 to 4.17.\n",
    " 21. compression-ratio:        continuous from 7 to 23.\n",
    " 22. horsepower:               continuous from 48 to 288.\n",
    " 23. peak-rpm:                 continuous from 4150 to 6600.\n",
    " 24. city-mpg:                 continuous from 13 to 49.\n",
    " 25. highway-mpg:              continuous from 16 to 54.\n",
    " 26. price:                    continuous from 5118 to 45400.\n",
    "\n",
    "8. Missing Attribute Values: (denoted by \"?\")\n",
    "   Attribute #:   Number of instances missing a value:\n",
    "   2.             41\n",
    "   6.             2\n",
    "   19.            4\n",
    "   20.            4\n",
    "   22.            2\n",
    "   23.            2\n",
    "   26.            4\n",
    "\n",
    "### Source Information\n",
    "   -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n",
    "   -- Date: 19 May 1987\n",
    "   -- Sources:\n",
    "     1) 1985 Model Import Car and Truck Specifications, 1985 Ward's\n",
    "        Automotive Yearbook.\n",
    "     2) Personal Auto Manuals, Insurance Services Office, 160 Water\n",
    "        Street, New York, NY 10038 \n",
    "     3) Insurance Collision Report, Insurance Institute for Highway\n",
    "        Safety, Watergate 600, Washington, DC 20037\n",
    "\n",
    "### Past Usage\n",
    "   -- Kibler,~D., Aha,~D.~W., \\& Albert,~M. (1989).  Instance-based prediction\n",
    "      of real-valued attributes.  {\\it Computational Intelligence}, {\\it 5},\n",
    "      51--57.\n",
    "\t -- Predicted price of car using all numeric and Boolean attributes\n",
    "\t -- Method: an instance-based learning (IBL) algorithm derived from a\n",
    "\t    localized k-nearest neighbor algorithm.  Compared with a\n",
    "\t    linear regression prediction...so all instances\n",
    "\t    with missing attribute values were discarded.  This resulted with\n",
    "\t    a training set of 159 instances, which was also used as a test\n",
    "\t    set (minus the actual instance during testing).\n",
    "\t -- Results: Percent Average Deviation Error of Prediction from Actual\n",
    "\t    -- 11.84% for the IBL algorithm\n",
    "\t    -- 14.12% for the resulting linear regression equation\n",
    "\n",
    "4. Relevant Information:\n",
    "   -- Description\n",
    "      This data set consists of three types of entities: (a) the\n",
    "      specification of an auto in terms of various characteristics, (b)\n",
    "      its assigned insurance risk rating, (c) its normalized losses in use\n",
    "      as compared to other cars.  The second rating corresponds to the\n",
    "      degree to which the auto is more risky than its price indicates.\n",
    "      Cars are initially assigned a risk factor symbol associated with its\n",
    "      price.   Then, if it is more risky (or less), this symbol is\n",
    "      adjusted by moving it up (or down) the scale.  Actuarians call this\n",
    "      process \"symboling\".  A value of +3 indicates that the auto is\n",
    "      risky, -3 that it is probably pretty safe.\n",
    "\n",
    "      The third factor is the relative average loss payment per insured\n",
    "      vehicle year.  This value is normalized for all autos within a\n",
    "      particular size classification (two-door small, station wagons,\n",
    "      sports/speciality, etc...), and represents the average loss per car\n",
    "      per year.\n",
    "\n",
    "   -- Note: Several of the attributes in the database could be used as a\n",
    "            \"class\" attribute.\n",
    "\n",
    "        '''\n",
    "        st.write(description)\n",
    "    else:\n",
    "        st.header('Automobile dataset')\n",
    "        df = load_data('../data/automobile_preprocessed.csv')\n",
    "        alpha = st.slider('Select param alpha', min_value=0.1, max_value=3.0, value=1.0, step=0.1, key='alpha')\n",
    "        fit_intercept = st.selectbox('Select fit intercept', [True, False], key='is_fit_intercept')\n",
    "        max_iter = st.slider('Select param max_iter', min_value=1, max_value=50, value=1, step=1, key='max_iter')\n",
    "        positive = st.selectbox('Select is all params are positive', [True, False], key='is_positive')\n",
    "        \n",
    "        parameters = {\n",
    "            'alpha': alpha,\n",
    "            'fit_intercept': fit_intercept,\n",
    "            'max_iter': max_iter,\n",
    "            'positive': positive\n",
    "        }\n",
    "        X_train, y_train, X_test, y_test = prepared_dataset(df)\n",
    "        \n",
    "        model = trainee_model(X_train, y_train, parameters)\n",
    "        process_prediction(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 00:21:48.028 WARNING root: \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
