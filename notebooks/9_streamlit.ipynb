{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деплой в Heroku\n",
    "\n",
    "https://test-ml-1.herokuapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet, Ridge, SGDRegressor\n",
    "import pickle\n",
    "import streamlit as st\n",
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем предобработку данных.\n",
    "\n",
    "Разделим данные на обучение и тест, нормализуем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache\n",
    "def prepared_dataset(df, random_state=None):\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df.price.astype('int64')\n",
    "    numeric_cols = np.array(['symboling', 'normalized_losses', 'wheel_base', 'length', 'width',\n",
    "       'height', 'curb_weight', 'num_of_cylinders', 'engine_size', 'bore',\n",
    "       'stroke', 'compression_ratio', 'horsepower', 'peak_rpm', 'city_mpg',\n",
    "       'highway_mpg'])\n",
    "    X_numeric = X.loc[:, numeric_cols]\n",
    "    categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))\n",
    "    X_categorical = X.loc[:, categorical_cols]\n",
    "    for col in categorical_cols:\n",
    "        X_categorical[col] = X_categorical[col].astype('string')\n",
    "    # Разделим на обучение и тест\n",
    "    X_train, X_test, X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(X, X_categorical, X_numeric, y, test_size=0.15, random_state=random_state)\n",
    "    # Номализуем значения\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_num)\n",
    "\n",
    "    X_train_num_sc = scaler.transform(X_train_num)\n",
    "    X_test_num_sc = scaler.transform(X_test_num)\n",
    "    # Соединяем значения воедино\n",
    "    X_train_transform = np.hstack((X_train_num_sc, X_train_cat))\n",
    "    X_test_transform = np.hstack((X_test_num_sc, X_test_cat))\n",
    "    return X_train_transform.astype('float32'), y_train.astype('float32'), X_test_transform.astype('float32'), y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(parameters={'input_shape':69, 'num_neurons':3, 'num_layers':1, 'activations':['relu'],\n",
    "                              'optimizer':'sgd', 'loss':'mse'}):\n",
    "    input_shape = parameters['input_shape']\n",
    "    num_neurons = parameters['num_neurons']\n",
    "    num_layers = parameters['num_layers']\n",
    "    activations = parameters['activations']\n",
    "    optimizer = parameters['optimizer']\n",
    "    loss = parameters['loss']\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation=activations[i]))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer, loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейные алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим доступные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model=\"\", parameters={}):\n",
    "    new_params = {}\n",
    "    if model == \"elastic_net\":\n",
    "        regressor = ElasticNet()\n",
    "    elif model == \"sgd_regressor\":\n",
    "        regressor = SGDRegressor()\n",
    "    elif model == \"ridge\":\n",
    "        regressor = Ridge()\n",
    "    elif model == 'neural_network':\n",
    "        return neural_network(parameters)\n",
    "    else:\n",
    "        regressor = ElasticNet()\n",
    "    # get all available parameters\n",
    "    available_params = set(regressor.get_params().keys()).intersection(set(parameters.keys()))\n",
    "    params = {a_p:parameters[a_p] for a_p in available_params}\n",
    "    regressor.set_params(**params)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras callback](https://keras.io/guides/writing_your_own_callbacks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(Callback):\n",
    "    def __init__(self, epochs=1):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.epochs = epochs\n",
    "        self.pr_bar = st.progress(0)\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        if epoch < self.epochs:\n",
    "            progress = float(epoch) / self.epochs\n",
    "        else:\n",
    "            progress = 100\n",
    "        self.pr_bar.progress(progress)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод <code>trainee_model</code> обучает модель с гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainee_model(X_train, y_train, model=\"\", parameters={'epochs':1}):\n",
    "    regressor = init_model(model, parameters)\n",
    "    if model == 'neural_network':\n",
    "        regressor.fit(X_train, y_train, epochs=parameters['epochs'],\n",
    "                     callbacks=[CustomCallback(parameters['epochs'])])\n",
    "    else:\n",
    "        regressor.fit(X_train, y_train)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод <code>process_prediction</code> выдает метрики качества для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prediction(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    st.write('R^2: {}'.format(r2_score(y_test, y_pred)))\n",
    "    st.write('MSE: {}'.format(mean_squared_error(y_test, y_pred)))\n",
    "    st.write('RMSE: {}'.format(mean_squared_error(y_test, y_pred, squared=False)))\n",
    "    st.write('MAE: {}'.format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сериализация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle [docs](https://docs.python.org/3/library/pickle.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сериализация в байтовое представление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_model(model):\n",
    "    return pickle.dumps(model)\n",
    "\n",
    "def deserialize_model(bin_data):\n",
    "    return pickle.loads(bin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сериализации/десериализации в/из файла можно использовать следующие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_model_file(model, filename=\"ser.dat\"):\n",
    "    with open(filename, 'wb') as fin:\n",
    "        pickle.dump(model, fin)\n",
    "    return filename\n",
    "\n",
    "def deserialize_model_file(filename=\"ser.dat\"):\n",
    "    with open(filename, 'rb') as fout:\n",
    "        model = pickle.load(fout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [STREAMLIT статья](https://www.notion.so/a53e9e35dc4f482f889e2a3f516be9fd) [docs](https://docs.streamlit.io/en/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache\n",
    "def load_description(filename='../data/automobile_description.md'):\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as fin:\n",
    "        descr_auto = fin.read()\n",
    "        return descr_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache\n",
    "def load_data(filename='../data/automobile_preprocessed.csv'):\n",
    "    df = pd.read_csv(filename, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    page = st.sidebar.selectbox('Choose a page', ['Description', 'Regressor'])\n",
    "    df = load_data('../data/automobile_preprocessed.csv')\n",
    "    if page == 'Description':\n",
    "        st.header('Automobile dataset description')\n",
    "        description_task = '''## Task 3\n",
    "Подготовьте данные, уберите аномалии. Разбейте датасет, проведите обучение моделей: \n",
    "- Линейная регрессия;\n",
    "- Регрессия дерева решений;\n",
    "- LASSO;\n",
    "- Гребневая регрессия;\n",
    "- Elastic Net регрессия.\n",
    "\n",
    "Найдите реализации методов в sklearn, оставьте в нотбуке ссылки на документацию. Найдите наилучшие гиперпараметры. Оцените качество моделей: R2, Mean Square Error(MSE), Root Mean Square Error(RMSE),  mean absolute error (MAE). Свои действия снабжайте пояснениями.'''\n",
    "        st.write(description_task)\n",
    "        st.dataframe(df)\n",
    "        description = load_description()\n",
    "        st.write(description)\n",
    "    else:\n",
    "        st.header('Automobile dataset')\n",
    "        # Set model type\n",
    "        model_type = st.selectbox('Select model', ['elastic_net', 'ridge', 'sgd_regressor', 'neural_network'])\n",
    "        parameters = {}\n",
    "        \n",
    "        if model_type in ['elastic_net', 'ridge', 'sgd_regressor']:\n",
    "            alpha = st.slider('Select param alpha', min_value=0.0, max_value=3.0, value=1.0, step=0.1, key='alpha')\n",
    "            parameters['alpha'] = alpha\n",
    "            \n",
    "        if model_type == 'elastic_net':\n",
    "            fit_intercept = st.selectbox('Select fit intercept', [True, False], key='is_fit_intercept')\n",
    "            parameters['fit_intercept'] = fit_intercept\n",
    "            max_iter = st.slider('Select param max_iter', min_value=1, max_value=50, value=1, step=1, key='max_iter')\n",
    "            parameters['max_iter'] = max_iter\n",
    "            positive = st.selectbox('Select is all params are positive', [True, False], key='is_positive')\n",
    "            parameters['positive'] = positive\n",
    "        elif model_type == 'ridge':\n",
    "            normalize = st.selectbox('Select if normalize parameters', [True, False], key='is_normalize')\n",
    "            parameters['normalize'] = normalize\n",
    "        elif model_type == 'sgd_regressor':\n",
    "            penalty = st.selectbox('Select penalty', ['l2', 'l1', 'elasticnet'], key='penalty')\n",
    "            parameters['penalty'] = penalty\n",
    "            if penalty == 'elasticnet':\n",
    "                l1_ratio = st.slider('Select param l1_ratio', min_value=0.0, max_value=1.0, value=0.5, step=0.05, key='l1_ratio')\n",
    "                parameters['l1_ratio'] = l1_ratio\n",
    "        elif model_type == 'neural_network':\n",
    "            num_layers = st.slider('Select number of layers', min_value=1, max_value=3, step=1, key='num_layers')\n",
    "            parameters['num_layers'] = num_layers\n",
    "            activations = []\n",
    "            for i in range(num_layers):\n",
    "                activation = st.selectbox('Select activation for {} layer'.format(i + 1), \n",
    "                                          ['relu', 'sigmoid', 'softmax', 'softsign', 'tanh', 'selu', 'elu', 'exponential'], \n",
    "                                          key='activation_{}'.format(i))\n",
    "                activations.append(activation)\n",
    "            parameters['activations'] = activations\n",
    "            num_neurons = st.slider('Select number of neurons on each hidden layer', min_value=1, max_value=10, step=1, key='num_neurons')\n",
    "            parameters['num_neurons'] = num_neurons\n",
    "            optimizer = st.selectbox('Select optimizer function', ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl'], key='optimizer')\n",
    "            parameters['optimizer'] = optimizer\n",
    "            loss = st.selectbox('Select loss function', ['mse', 'mae'], key='loss')\n",
    "            parameters['loss'] = loss\n",
    "            epochs = st.slider('Select number of epochs', min_value=1, max_value=2000, value=1, step=6, key='epochs')\n",
    "            parameters['epochs'] = epochs\n",
    "\n",
    "        X_train, y_train, X_test, y_test = prepared_dataset(df)\n",
    "        if model_type == 'neural_network':\n",
    "            input_shape = X_train.shape[1]\n",
    "            parameters['input_shape'] = input_shape\n",
    "        model = trainee_model(X_train, y_train, model=model_type, parameters=parameters)\n",
    "        if model_type != 'neural_network':\n",
    "            # Сериализация модели\n",
    "            model_bytes = serialize_model(model)\n",
    "            # Десериализация модели\n",
    "            model_deser = deserialize_model(model_bytes)\n",
    "        process_prediction(model, X_test, y_test)\n",
    "    st.write(\"By Konstantin Ushakov, 2021.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-19 16:50:57.695 WARNING root: \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\ProgramFiles\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
