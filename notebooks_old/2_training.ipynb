{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree, naive_bayes, svm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')\n",
    "\n",
    "from training_realization import Classifier_SVM, Classifier_NB_bin, Classifier_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank_additional_preprocessed.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 70 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age                            41188 non-null  int64  \n",
      " 1   campaign                       41188 non-null  int64  \n",
      " 2   pdays                          41188 non-null  int64  \n",
      " 3   emp.var.rate                   41188 non-null  float64\n",
      " 4   cons.price.idx                 41188 non-null  float64\n",
      " 5   cons.conf.idx                  41188 non-null  float64\n",
      " 6   euribor3m                      41188 non-null  float64\n",
      " 7   nr.employed                    41188 non-null  float64\n",
      " 8   y                              41188 non-null  int64  \n",
      " 9   job_admin.                     41188 non-null  int64  \n",
      " 10  job_blue-collar                41188 non-null  int64  \n",
      " 11  job_entrepreneur               41188 non-null  int64  \n",
      " 12  job_housemaid                  41188 non-null  int64  \n",
      " 13  job_management                 41188 non-null  int64  \n",
      " 14  job_retired                    41188 non-null  int64  \n",
      " 15  job_self-employed              41188 non-null  int64  \n",
      " 16  job_services                   41188 non-null  int64  \n",
      " 17  job_student                    41188 non-null  int64  \n",
      " 18  job_technician                 41188 non-null  int64  \n",
      " 19  job_unemployed                 41188 non-null  int64  \n",
      " 20  job_unknown                    41188 non-null  int64  \n",
      " 21  marital_divorced               41188 non-null  int64  \n",
      " 22  marital_married                41188 non-null  int64  \n",
      " 23  marital_single                 41188 non-null  int64  \n",
      " 24  marital_unknown                41188 non-null  int64  \n",
      " 25  education_basic.4y             41188 non-null  int64  \n",
      " 26  education_basic.6y             41188 non-null  int64  \n",
      " 27  education_basic.9y             41188 non-null  int64  \n",
      " 28  education_high.school          41188 non-null  int64  \n",
      " 29  education_illiterate           41188 non-null  int64  \n",
      " 30  education_professional.course  41188 non-null  int64  \n",
      " 31  education_university.degree    41188 non-null  int64  \n",
      " 32  education_unknown              41188 non-null  int64  \n",
      " 33  default_no                     41188 non-null  int64  \n",
      " 34  default_unknown                41188 non-null  int64  \n",
      " 35  default_yes                    41188 non-null  int64  \n",
      " 36  housing_no                     41188 non-null  int64  \n",
      " 37  housing_unknown                41188 non-null  int64  \n",
      " 38  housing_yes                    41188 non-null  int64  \n",
      " 39  loan_no                        41188 non-null  int64  \n",
      " 40  loan_unknown                   41188 non-null  int64  \n",
      " 41  loan_yes                       41188 non-null  int64  \n",
      " 42  contact_cellular               41188 non-null  int64  \n",
      " 43  contact_telephone              41188 non-null  int64  \n",
      " 44  month_apr                      41188 non-null  int64  \n",
      " 45  month_aug                      41188 non-null  int64  \n",
      " 46  month_dec                      41188 non-null  int64  \n",
      " 47  month_jul                      41188 non-null  int64  \n",
      " 48  month_jun                      41188 non-null  int64  \n",
      " 49  month_mar                      41188 non-null  int64  \n",
      " 50  month_may                      41188 non-null  int64  \n",
      " 51  month_nov                      41188 non-null  int64  \n",
      " 52  month_oct                      41188 non-null  int64  \n",
      " 53  month_sep                      41188 non-null  int64  \n",
      " 54  day_of_week_fri                41188 non-null  int64  \n",
      " 55  day_of_week_mon                41188 non-null  int64  \n",
      " 56  day_of_week_thu                41188 non-null  int64  \n",
      " 57  day_of_week_tue                41188 non-null  int64  \n",
      " 58  day_of_week_wed                41188 non-null  int64  \n",
      " 59  poutcome_failure               41188 non-null  int64  \n",
      " 60  poutcome_nonexistent           41188 non-null  int64  \n",
      " 61  poutcome_success               41188 non-null  int64  \n",
      " 62  previous_0                     41188 non-null  int64  \n",
      " 63  previous_1                     41188 non-null  int64  \n",
      " 64  previous_2                     41188 non-null  int64  \n",
      " 65  previous_3                     41188 non-null  int64  \n",
      " 66  previous_4                     41188 non-null  int64  \n",
      " 67  previous_5                     41188 non-null  int64  \n",
      " 68  previous_6                     41188 non-null  int64  \n",
      " 69  previous_7                     41188 non-null  int64  \n",
      "dtypes: float64(5), int64(65)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим данные на обучение и тест, нормализуем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства обработки разделим признаки на категориальные и вещественные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = np.array(['age', 'campaign', 'pdays', 'emp.var.rate', 'cons.price.idx', \n",
    "           'cons.conf.idx', 'euribor3m', 'nr.employed'])\n",
    "X_numeric = X[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-45ba4a5426bd>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_categorical[col] = X_categorical[col].astype('string')\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))\n",
    "X_categorical = X[categorical_cols]\n",
    "for col in categorical_cols:\n",
    "    X_categorical[col] = X_categorical[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n"
      " 0   job_unemployed                 41188 non-null  string\n",
      " 1   contact_cellular               41188 non-null  string\n",
      " 2   job_admin.                     41188 non-null  string\n",
      " 3   education_illiterate           41188 non-null  string\n",
      " 4   marital_unknown                41188 non-null  string\n",
      " 5   education_basic.4y             41188 non-null  string\n",
      " 6   loan_unknown                   41188 non-null  string\n",
      " 7   housing_no                     41188 non-null  string\n",
      " 8   education_basic.6y             41188 non-null  string\n",
      " 9   default_yes                    41188 non-null  string\n",
      " 10  previous_2                     41188 non-null  string\n",
      " 11  previous_1                     41188 non-null  string\n",
      " 12  previous_3                     41188 non-null  string\n",
      " 13  marital_divorced               41188 non-null  string\n",
      " 14  month_nov                      41188 non-null  string\n",
      " 15  job_unknown                    41188 non-null  string\n",
      " 16  poutcome_success               41188 non-null  string\n",
      " 17  day_of_week_mon                41188 non-null  string\n",
      " 18  job_entrepreneur               41188 non-null  string\n",
      " 19  month_aug                      41188 non-null  string\n",
      " 20  housing_yes                    41188 non-null  string\n",
      " 21  month_apr                      41188 non-null  string\n",
      " 22  marital_single                 41188 non-null  string\n",
      " 23  day_of_week_tue                41188 non-null  string\n",
      " 24  education_basic.9y             41188 non-null  string\n",
      " 25  job_housemaid                  41188 non-null  string\n",
      " 26  education_high.school          41188 non-null  string\n",
      " 27  month_dec                      41188 non-null  string\n",
      " 28  marital_married                41188 non-null  string\n",
      " 29  month_jul                      41188 non-null  string\n",
      " 30  housing_unknown                41188 non-null  string\n",
      " 31  job_student                    41188 non-null  string\n",
      " 32  job_technician                 41188 non-null  string\n",
      " 33  month_oct                      41188 non-null  string\n",
      " 34  job_management                 41188 non-null  string\n",
      " 35  job_retired                    41188 non-null  string\n",
      " 36  education_unknown              41188 non-null  string\n",
      " 37  previous_0                     41188 non-null  string\n",
      " 38  job_services                   41188 non-null  string\n",
      " 39  job_blue-collar                41188 non-null  string\n",
      " 40  loan_yes                       41188 non-null  string\n",
      " 41  previous_7                     41188 non-null  string\n",
      " 42  job_self-employed              41188 non-null  string\n",
      " 43  day_of_week_wed                41188 non-null  string\n",
      " 44  previous_6                     41188 non-null  string\n",
      " 45  loan_no                        41188 non-null  string\n",
      " 46  previous_4                     41188 non-null  string\n",
      " 47  education_professional.course  41188 non-null  string\n",
      " 48  month_may                      41188 non-null  string\n",
      " 49  default_no                     41188 non-null  string\n",
      " 50  month_sep                      41188 non-null  string\n",
      " 51  previous_5                     41188 non-null  string\n",
      " 52  day_of_week_fri                41188 non-null  string\n",
      " 53  poutcome_failure               41188 non-null  string\n",
      " 54  default_unknown                41188 non-null  string\n",
      " 55  month_jun                      41188 non-null  string\n",
      " 56  contact_telephone              41188 non-null  string\n",
      " 57  month_mar                      41188 non-null  string\n",
      " 58  education_university.degree    41188 non-null  string\n",
      " 59  day_of_week_thu                41188 non-null  string\n",
      " 60  poutcome_nonexistent           41188 non-null  string\n",
      "dtypes: string(61)\n",
      "memory usage: 19.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_train_cat, X_test_cat, X_train_num, X_test_num, y_train, y_test = train_test_split(X, X_categorical, X_numeric, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализируем значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_num)\n",
    "\n",
    "X_train_num_sc = scaler.transform(X_train_num)\n",
    "X_test_num_sc = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединяем воедино все значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform = np.hstack((X_train_num_sc, X_train_cat))\n",
    "X_test_transform = np.hstack((X_test_num_sc, X_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      9141\n",
      "           1       0.51      0.29      0.37      1156\n",
      "\n",
      "    accuracy                           0.89     10297\n",
      "   macro avg       0.71      0.63      0.65     10297\n",
      "weighted avg       0.87      0.89      0.88     10297\n",
      "\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_KNN = KNeighborsClassifier()\n",
    "classifier_KNN.fit(X_train_transform, y_train)\n",
    "y_pred_KNN = classifier_KNN.predict(X_test_transform)\n",
    "score_KNN = classification_report(y_test, y_pred_KNN)\n",
    "\n",
    "print(score_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      9141\n",
      "           1       0.30      0.33      0.31      1156\n",
      "\n",
      "    accuracy                           0.84     10297\n",
      "   macro avg       0.60      0.62      0.61     10297\n",
      "weighted avg       0.84      0.84      0.84     10297\n",
      "\n",
      "Wall time: 656 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_DTC = tree.DecisionTreeClassifier()\n",
    "classifier_DTC.fit(X_train_transform, y_train)\n",
    "y_pred_DTC = classifier_DTC.predict(X_test_transform)\n",
    "score_DTC = classification_report(y_test, y_pred_DTC)\n",
    "\n",
    "print(score_DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88      9141\n",
      "           1       0.30      0.60      0.40      1156\n",
      "\n",
      "    accuracy                           0.80     10297\n",
      "   macro avg       0.62      0.71      0.64     10297\n",
      "weighted avg       0.87      0.80      0.82     10297\n",
      "\n",
      "Wall time: 457 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_NB = naive_bayes.GaussianNB()\n",
    "classifier_NB.fit(X_train_transform, y_train)\n",
    "y_pred_NB = classifier_NB.predict(X_test_transform)\n",
    "score_NB = classification_report(y_test, y_pred_NB)\n",
    "\n",
    "print(score_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94      9141\n",
      "           1       0.63      0.18      0.29      1156\n",
      "\n",
      "    accuracy                           0.90     10297\n",
      "   macro avg       0.77      0.59      0.61     10297\n",
      "weighted avg       0.87      0.90      0.87     10297\n",
      "\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_CVM = svm.SVC(kernel='linear')\n",
    "classifier_CVM.fit(X_train_transform, y_train)\n",
    "y_pred_CVM = classifier_CVM.predict(X_test_transform)\n",
    "score_CVM = classification_report(y_test, y_pred_CVM)\n",
    "\n",
    "print(score_CVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      9141\n",
      "           1       0.36      0.63      0.46      1156\n",
      "\n",
      "    accuracy                           0.83     10297\n",
      "   macro avg       0.65      0.74      0.68     10297\n",
      "weighted avg       0.88      0.83      0.85     10297\n",
      "\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_LR = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "classifier_LR.fit(X_train_transform, y_train)\n",
    "y_pred_LR = classifier_LR.predict(X_test_transform)\n",
    "score_LR = classification_report(y_test, y_pred_LR)\n",
    "\n",
    "print(score_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5]}\n",
    "\n",
    "classifier_KNN = KNeighborsClassifier()\n",
    "\n",
    "clf_KNN = GridSearchCV(classifier_KNN, parameters)\n",
    "clf_KNN.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=4)\n"
     ]
    }
   ],
   "source": [
    "best_estimator_KNN = clf_KNN.best_estimator_\n",
    "\n",
    "print(best_estimator_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 10, 100],\n",
       "                         'min_samples_split': [2, 3, 5, 8]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [1, 3, 5, 10, 100],\n",
    "    'min_samples_split': [2, 3, 5, 8]\n",
    "}\n",
    "\n",
    "classifier_DTC = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf_DTC = GridSearchCV(classifier_DTC, parameters)\n",
    "clf_DTC.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5)\n"
     ]
    }
   ],
   "source": [
    "best_estimator_DTC = clf_DTC.best_estimator_\n",
    "\n",
    "print(best_estimator_DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': [1e-10, 1e-09, 1e-08, 1e-05, 0.01,\n",
       "                                           0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\n",
    "    'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-5, 1e-2, 1e-1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "classifier_NB = naive_bayes.GaussianNB()\n",
    "\n",
    "clf_NB = GridSearchCV(classifier_NB, parameters)\n",
    "clf_NB.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1)\n"
     ]
    }
   ],
   "source": [
    "best_estimator_NB = clf_NB.best_estimator_\n",
    "\n",
    "print(best_estimator_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), param_grid={'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "classifier_CVM = svm.SVC()\n",
    "\n",
    "clf_CVM = GridSearchCV(classifier_CVM, parameters, cv=3)\n",
    "clf_CVM.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n"
     ]
    }
   ],
   "source": [
    "best_estimator_CVM = clf_CVM.best_estimator_\n",
    "\n",
    "print(best_estimator_CVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'class_weight': ['balanced'], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'newton-cg']})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\n",
    "    'class_weight': ['balanced'],\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "classifier_LR = LogisticRegression()\n",
    "\n",
    "clf_LR = GridSearchCV(classifier_LR, parameters, cv=3)\n",
    "clf_LR.fit(X_train_transform, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "best_estimator_LR = clf_LR.best_estimator_\n",
    "\n",
    "print(best_estimator_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-69c41c288556>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_transform_int[col] = X_train_transform_int[col].astype('float64')\n",
      "<ipython-input-11-69c41c288556>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_transform_int[col] = X_test_transform_int[col].astype('float64')\n"
     ]
    }
   ],
   "source": [
    "cols = list(set(X.columns.values.tolist()))\n",
    "\n",
    "X_train_transform_int = X_train\n",
    "for col in cols:\n",
    "    X_train_transform_int[col] = X_train_transform_int[col].astype('float64')\n",
    "    \n",
    "X_test_transform_int = X_test\n",
    "for col in cols:\n",
    "    X_test_transform_int[col] = X_test_transform_int[col].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как алгоритм работает медленнее встроенного, вычислим предсказания на 1000 объектах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_classifier_KNN = Classifier_KNN()\n",
    "user_classifier_KNN.fit(X_train_transform_int.values, y_train.values)\n",
    "y_user_pred_KNN = user_classifier_KNN.predict(X_test_transform_int.values[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (0.0, 0), (0.0, 0), (0.0, 1), (1.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       892\n",
      "           1       0.54      0.31      0.40       108\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.73      0.64      0.67      1000\n",
      "weighted avg       0.88      0.90      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(y_user_pred_KNN[:30], y_test.values[:30])))\n",
    "score_user_KNN = classification_report(y_test.values[:1000], y_user_pred_KNN)\n",
    "\n",
    "print(score_user_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a(x) = argmax_y P(x|y)P(y)$\n",
    "\n",
    "$P(x|y) = P(x_1 | y)P(x_2 | y)...P(x_N | y)$, где $x_k$ - $k$-ый признак объекта $x$\n",
    "\n",
    "$P(y) = \\frac{l_y}{l}$\n",
    "\n",
    "Бинарные признаки:\n",
    "\n",
    "$P(x_k | y) = \\frac{1}{l_y} доля(x_k, y)$\n",
    "\n",
    "Числовые признаки:\n",
    "\n",
    "Восстановить распределение (более сложные методы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничимся рассмотрением только бинарных признаков (либо любых числовых, с разделителем 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_NB_bin:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Для бинарных значений класса\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes = np.array(list(set(y_train)))\n",
    "        self.n_class = self.classes.shape[0]\n",
    "        # Сохраняем созданные значения\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.p = np.array([])\n",
    "        self.l_y = np.array([])\n",
    "        # Считаем вероятности каждого класса\n",
    "        for i in range(self.n_class):\n",
    "            self.l_y = np.append(self.l_y, np.sum([1 if y == self.classes[i] else 0 for y in y_train]))\n",
    "            self.p = np.append(self.p, self.l_y[i] / X_train.shape[0])\n",
    "        # каждая пара - это доля объектов, принадлежащих к классу (x,y) по тестовой выборке:\n",
    "        # (x_i, y) = [[(y_0, 0), (y_0, 1)], ..., [(y_i, 0), (y_i, 1)], ..., [(y_n, 0), (y_n, n)]]\n",
    "        # Инициализируем массив таких кортежей\n",
    "        count_p_x_0 = np.array([np.array([0 for j in range(self.n_class)]) for i in range(X_train.shape[1])])\n",
    "        count_p_x_1 = np.array([np.array([0 for j in range(self.n_class)]) for i in range(X_train.shape[1])])\n",
    "        \n",
    "        for x, y in list(zip(X_train, y_train)):\n",
    "            j, = np.where(y == self.classes)\n",
    "            # Для каждого признака x_i заносим в класс значение\n",
    "            for i, x_i in enumerate(x):\n",
    "                # x - бинарный признак, принимает значения 0 и 1\n",
    "                if x_i > 0.5:\n",
    "                    # y, 1\n",
    "                    count_p_x_1[i][j[0]] += 1\n",
    "                else:\n",
    "                    # y, 0\n",
    "                    count_p_x_0[i][j[0]] += 1\n",
    "        # Считаем долю признаков каждого типа - делим на число записей в обучении (l_y)\n",
    "        \n",
    "        self.p_x_0 = count_p_x_0 / (np.array([self.l_y for x in range(X_train.shape[1])]))\n",
    "        self.p_x_1 = count_p_x_1 / (np.array([self.l_y for x in range(X_train.shape[1])]))\n",
    "        print(self.l_y)\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # Создаем массив предсказанных значений\n",
    "        y_pred = np.array([])\n",
    "        for x in X_test:\n",
    "            # Вычисляем вероятность принадлежать к каждому классу\n",
    "            # Инициализируем вероятностями принадлежности i-му классу\n",
    "            p_x = np.array(self.p, copy=True)\n",
    "            for i, x_i in enumerate(x):\n",
    "                if x_i > 0.5:\n",
    "                    p_x *= self.p_x_1[i]\n",
    "                else:\n",
    "                    p_x *= self.p_x_0[i]\n",
    "            #Находим индекс самого вероятного класса\n",
    "            j, = np.where(p_x == np.max(p_x))\n",
    "            y_cur = self.classes[j[0]]\n",
    "            y_pred = np.append(y_pred, y_cur)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-e731fd52fcc1>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_transform_int[col] = X_train_transform_int[col].astype('int64')\n",
      "<ipython-input-32-e731fd52fcc1>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_transform_int[col] = X_test_transform_int[col].astype('int64')\n"
     ]
    }
   ],
   "source": [
    "X_train_transform_int = X_train_cat\n",
    "for col in categorical_cols:\n",
    "    X_train_transform_int[col] = X_train_transform_int[col].astype('int64')\n",
    "    \n",
    "X_test_transform_int = X_test_cat\n",
    "for col in categorical_cols:\n",
    "    X_test_transform_int[col] = X_test_transform_int[col].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения типа scalar отлично подходят - они равномерно распределены на 0...1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform_NB = np.hstack((X_train_num_sc, X_train_transform_int))\n",
    "X_test_transform_NB = np.hstack((X_test_num_sc, X_test_transform_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30891, 69) (30891,)\n",
      "(10297, 69) (10297,)\n",
      "Start\n",
      "[27407.  3484.]\n",
      "results shape:  (10297,) (10297,)\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(X_train_transform_NB.shape, y_train.shape)\n",
    "print(X_test_transform_NB.shape, y_test.shape)\n",
    "print('Start')\n",
    "\n",
    "user_classifier_NB = Classifier_NB_bin()\n",
    "user_classifier_NB.fit(X_train_transform_NB, y_train.values)\n",
    "y_user_pred_NB = user_classifier_NB.predict(X_test_transform_NB)\n",
    "\n",
    "print('results shape: ', y_user_pred_NB.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87      9141\n",
      "           1       0.28      0.57      0.38      1156\n",
      "\n",
      "    accuracy                           0.79     10297\n",
      "   macro avg       0.61      0.69      0.62     10297\n",
      "weighted avg       0.86      0.79      0.82     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_user_KNN = classification_report(y_test.values, y_user_pred_NB)\n",
    "\n",
    "print(score_user_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hingeloss: $H = max(0, 1 - y (w^T x))$\n",
    "\n",
    "Зазор margin: $m = y (w^T x)$\n",
    "\n",
    "Soft-margin SVM (Q): $max(0, 1 - y w^T x) + \\alpha (w^T w) / 2$\n",
    "\n",
    "$\\eta$ - eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторская реализация (https://habr.com/ru/company/ods/blog/484148/) (soft-margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_feature(a):\n",
    "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "    a_extended[:,:-1] = a\n",
    "    a_extended[:,-1] = int(1)  \n",
    "    return a_extended\n",
    "\n",
    "\n",
    "class Classifier_SVM_realized(object):\n",
    "    \n",
    "    __class__ = \"CustomSVM\"\n",
    "    __doc__ = \"\"\"\n",
    "    This is an implementation of the SVM classification algorithm\n",
    "    Note that it works only for binary classification\n",
    "    \n",
    "    #############################################################\n",
    "    ######################   PARAMETERS    ######################\n",
    "    #############################################################\n",
    "    \n",
    "    etha: float(default - 0.01)\n",
    "        Learning rate, gradient step\n",
    "        \n",
    "    alpha: float, (default - 1.0)\n",
    "        Regularization parameter in 0.5*alpha*||w||^2\n",
    "        \n",
    "    epochs: int, (default - 200)\n",
    "        Number of epochs of training\n",
    "      \n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, etha=0.01, alpha=0.1, epochs=200):\n",
    "        self._epochs = epochs\n",
    "        self._etha = etha\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "    \n",
    "\n",
    "    def fit(self, X_train, Y_train, verbose=False): #arrays: X; Y =-1,1\n",
    "        \n",
    "        if len(set(Y_train)) != 2:\n",
    "            raise ValueError(\"Number of classes in Y is not equal 2!\")\n",
    "        \n",
    "        X_train = add_bias_feature(X_train)\n",
    "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])\n",
    "        \n",
    "        for epoch in range(self._epochs):\n",
    "            for i,x in enumerate(X_train):\n",
    "                margin = Y_train[i]*np.dot(self._w,X_train[i])\n",
    "                if margin >= 1: # классифицируем верно\n",
    "                    self._w = self._w - self._etha*self._alpha*self._w/self._epochs\n",
    "                else: # классифицируем неверно или попадаем на полосу разделения при 0<m<1\n",
    "                    self._w = self._w + self._etha*(Y_train[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X:np.array) -> np.array:\n",
    "        y_pred = []\n",
    "        X_extended = add_bias_feature(X)\n",
    "        for i in range(len(X_extended)):\n",
    "            sign = np.sign(np.dot(self._w,X_extended[i]))\n",
    "            if sign > 0.5:\n",
    "                y_pred = np.append(y_pred, 1)\n",
    "            else:\n",
    "                y_pred = np.append(y_pred, 0)\n",
    "            \n",
    "        return np.array(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация (soft_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones(x):\n",
    "    ones = np.ones(x.shape[0])\n",
    "    ones = np.reshape(ones, (ones.shape[0], 1))\n",
    "    return np.hstack((x, ones))\n",
    "        \n",
    "class Classifier_SVM:\n",
    "    def __init__(self, eta=1e-2, alpha=1e-1, epochs=200):\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train = X_train.astype(np.int)\n",
    "        # Сохраняем созданные значения\n",
    "        self.X_train = add_ones(X_train).astype(np.int)\n",
    "        self.y_train = y_train.astype(np.int)\n",
    "        # Начинаем с w = [0, 0, ..., 0]\n",
    "        # self._w = np.zeros(self.X_train.shape[1])\n",
    "        self._w = np.random.normal(loc=0, scale=0.05, size=self.X_train.shape[1])\n",
    "        # C = eta * alpha / epochs\n",
    "        C = self.eta * self.alpha / self.epochs\n",
    "        for epoch in range(self.epochs):\n",
    "            for j, x in enumerate(self.X_train):\n",
    "                # w = w - eta * grad(Q)\n",
    "                margin_cur = self.y_train[j] * np.dot(self._w, x)\n",
    "                if margin_cur >= 1:\n",
    "                    # ywx >= 1 => hinde_loss = 0 - правильная классификация\n",
    "                    # grad(Q) = alpha * w\n",
    "                    self._w += - C * self._w\n",
    "                else:\n",
    "                    # ywx < 1 => hinde_loss > 0 - неправильная классификация\n",
    "                    # grad(Q) = alpha * w - yx\n",
    "                    self._w += - C * self._w + self.eta * self.y_train[j] * x\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # Создаем массив предсказанных значений\n",
    "        y_pred = np.array([])\n",
    "        x_ext = add_ones(X_test)\n",
    "        # Предсказываем как линейную модель y = wx\n",
    "        # Так как только для бинарной классификации, берем знак\n",
    "        for x in x_ext:\n",
    "            sign = np.sign(np.dot(self._w, x))\n",
    "            if sign > 0.5:\n",
    "                y_pred = np.append(y_pred, 1)\n",
    "            else:\n",
    "                y_pred = np.append(y_pred, 0)\n",
    "        return y_pred\n",
    "    \n",
    "    def hinde_loss(self, x, y):\n",
    "        return np.max(0, 1 - self.margin(x, y))\n",
    "    \n",
    "    def margin(self, x, y):\n",
    "        return y * np.dot(x, self._w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform_SVM = X_train_transform.astype(np.int)\n",
    "X_test_transform_SVM = X_test_transform.astype(np.int)\n",
    "y_train_transform_SVM = y_train.values.astype(np.int)\n",
    "y_test_transform_SVM = y_test.values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results shape:  (10297,) (10297,)\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_classifier_SVM = Classifier_SVM(epochs=100)\n",
    "user_classifier_SVM.fit(X_train_transform_SVM, y_train_transform_SVM)\n",
    "y_user_pred_SVM = user_classifier_SVM.predict(X_test_transform_SVM)\n",
    "\n",
    "print('results shape: ', y_user_pred_SVM.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9141\n",
      "           1       0.11      1.00      0.20      1156\n",
      "\n",
      "    accuracy                           0.11     10297\n",
      "   macro avg       0.06      0.50      0.10     10297\n",
      "weighted avg       0.01      0.11      0.02     10297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "user_classifier_SVM = classification_report(y_test.values, y_user_pred_SVM)\n",
    "\n",
    "print(user_classifier_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим побольше штраф за ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10297,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.35      0.50      9141\n",
      "           1       0.10      0.60      0.18      1156\n",
      "\n",
      "    accuracy                           0.38     10297\n",
      "   macro avg       0.49      0.48      0.34     10297\n",
      "weighted avg       0.79      0.38      0.47     10297\n",
      "\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_classifier_SVM = Classifier_SVM(epochs=200, eta=1e-9, alpha=1e-9)\n",
    "user_classifier_SVM.fit(X_train_transform_SVM, y_train_transform_SVM)\n",
    "y_user_pred_SVM = user_classifier_SVM.predict(X_test_transform_SVM)\n",
    "print(y_user_pred_SVM.shape)\n",
    "user_classifier_SVM = classification_report(y_test.values, y_user_pred_SVM)\n",
    "\n",
    "print(user_classifier_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.42      0.57      9141\n",
      "           1       0.13      0.72      0.23      1156\n",
      "\n",
      "    accuracy                           0.45     10297\n",
      "   macro avg       0.53      0.57      0.40     10297\n",
      "weighted avg       0.83      0.45      0.53     10297\n",
      "\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_classifier_SVM = Classifier_SVM_realized(epochs=200, etha=1e-9, alpha=1e-9)\n",
    "user_classifier_SVM.fit(X_train_transform_SVM, y_train_transform_SVM)\n",
    "y_user_pred_SVM = user_classifier_SVM.predict(X_test_transform_SVM)\n",
    "\n",
    "user_classifier_SVM = classification_report(y_test.values, y_user_pred_SVM)\n",
    "\n",
    "print(user_classifier_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
